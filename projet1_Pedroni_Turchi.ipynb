{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gabriele Pedroni (ENSIIE - M2DS)\n",
        "\n",
        "Lorenzo Turchi (ENSIIE - M2QF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QK2nzhm6k3X"
      },
      "source": [
        "# Classification model for a real application: the Heart dataset\n",
        "The “SAheart.txt” dataset stored a n = 462 sample of males in a heart-disease high-risk region of the Western Cape,\n",
        "South Africa. In this section, the aim of the work is studying classification models to be able to predict the value of the “chd” response variable (coronary heart disease), given the other variables (p = 10).\n",
        "\n",
        "In the next passages, we have imported all the necessaries libraries and extracted the quantitative co-variables (X) and the target response (Y) of this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.tree import export_text\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "UDQfOmKg7ONp",
        "outputId": "6e2ede38-5c4b-4992-aead-430e08be922e"
      },
      "outputs": [],
      "source": [
        "#Application SA Heart\n",
        "tab = pd.read_csv('SAheart.txt')\n",
        "print(tab)\n",
        "np.shape(tab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LiBY_jL7gQI"
      },
      "source": [
        "These are the covariates in our dataset:\n",
        "*   sbp: systolic blood pressure\n",
        "*   tobacco: cumulative tobacco (kg)\n",
        "*   ldl: low density lipoprotein cholesterol\n",
        "*   adiposity: not recorded in source; maybe another measurement of obesity similar to BMI.\n",
        "*   famhist: family history of heart disease (Present, Absent)\n",
        "*   typea: type-A behavior\n",
        "*   obesity: A measure of obesity; body mass index (or BMI) is consistent with Rossouw et al. (1983). Having BMI >= 30 scored as \"obese\" by Rossouw et al. (1983).\n",
        "*   alcohol: current alcohol consumption\n",
        "*   age: age at onset\n",
        "*   chd: coronary heart disease (response variable)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "jnUPemtV-rmd",
        "outputId": "51745bbe-4c50-4c81-8035-b972d1b969f0"
      },
      "outputs": [],
      "source": [
        "print(tab.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "AZzQ7k38EQV8",
        "outputId": "86920306-614f-42fc-fd18-f5634a9091f6"
      },
      "outputs": [],
      "source": [
        "Y=tab[\"chd\"]\n",
        "Xnum=tab.loc[:,['sbp','tobacco','ldl','adiposity','typea','obesity','alcohol','age']]\n",
        "X=Xnum.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKGQ0NOVzLej"
      },
      "source": [
        "In this problem, we cannot generate a test set. For this reason, we need to split our dataset into training set and the test set through an arbitrary threshold that will define the proportion of data that will compose the test set. The remaing data will form the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "md8ZvpjF2Z0w"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following step represents the data normalization necessary in order to conduct a meaningful analysis. The key theoretical concept in what we are about to do is that we have to act as if we are in possession only of the training set, so our scaler must be defined according to the data in X_train and then we have to normalize X_test according to the same scaler (which might seem counter intuitive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following classification methods are tested, in the following order:\n",
        "- Naive Bayes\n",
        "- Linear Discrimination Analysis\n",
        "- Quadratic Discrimination Analysis\n",
        "- Logistic Regression\n",
        "- Decision Tree Classifier\n",
        "- Bagging\n",
        "- Random Forest\n",
        "- Adaboost\n",
        "- Gradient Boosting\n",
        "- Stacking\n",
        "\n",
        "We decided to not use K-Nearest-Neighbor classifier because as we saw during the lecture (lecture 1, slide 43), the euclidean distance loses its discrimination ability in high dimensional spaces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Naive Bayes: model calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nb = GaussianNB()\n",
        "nb_fit = nb.fit(X_train, y_train)\n",
        "\n",
        "pY_test=nb_fit.predict_proba(X_test)\n",
        "predxclass=np.argmax(pY_test,axis=1)\n",
        "print(predxclass)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Naive Bayes: evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nb_accuracy = accuracy_score(y_test, predxclass)\n",
        "nb_precision = precision_score(y_test, predxclass)\n",
        "nb_recall = recall_score(y_test, predxclass)\n",
        "nb_f1_score = f1_score(y_test, predxclass)\n",
        "\n",
        "print(f\"Accuracy using NB is: {nb_accuracy:.3f}\")\n",
        "print(f\"Precision using NB is: {nb_precision:.3f}\")\n",
        "print(f\"Recall using NB is: {nb_recall:.3f}\")\n",
        "print(f\"F1-score using NB is: {nb_f1_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Naive Bayes: ROC curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To have another metric to compare the various classification methods, we think it is useful to visualize the ROC curve and to compute the AUC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nb_y_prob_1 = pY_test[:, 1]\n",
        "nb_FPR, nb_TPR, nb_threshold = roc_curve(y_test, nb_y_prob_1)\n",
        "\n",
        "figure = plt.figure(figsize=(4,2))\n",
        "plt.plot(nb_FPR, nb_TPR, linewidth=2)\n",
        "plt.title('Naive Bayes. ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(nb_TPR, nb_TPR, \"k--\", linewidth = 2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "nb_y_pred = nb_fit.predict(X_test)\n",
        "nb_auc_score = roc_auc_score(y_test, nb_y_pred)\n",
        "print(f\"The area under the ROC Curve, using Naive Bayes Classifier is: {nb_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LDA: model calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lda = LinearDiscriminantAnalysis()\n",
        "lda_fit = lda.fit(X_train, y_train)\n",
        "\n",
        "predxclass = lda.predict(X_test)\n",
        "pY_test = lda_fit.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LDA: evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lda_accuracy = accuracy_score(y_test, predxclass)\n",
        "lda_precision = precision_score(y_test, predxclass)\n",
        "lda_recall = recall_score(y_test, predxclass)\n",
        "lda_f1_score = f1_score(y_test, predxclass)\n",
        "\n",
        "print(f\"Accuracy using LDA is: {lda_accuracy:.3f}\")\n",
        "print(f\"Precision using LDA is: {lda_precision:.3f}\")\n",
        "print(f\"Recall using LDA is: {lda_recall:.3f}\")\n",
        "print(f\"F1-score using LDA is: {lda_f1_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LDA: ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lda_y_prob_1 = pY_test[:, 1]\n",
        "lda_FPR, lda_TPR, lda_threshold = roc_curve(y_test, lda_y_prob_1)\n",
        "\n",
        "figure = plt.figure(figsize=(4,2))\n",
        "plt.plot(lda_FPR, lda_TPR, linewidth=2)\n",
        "plt.title('Linear Discriminant Analysis. ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(lda_TPR, lda_TPR, \"k--\", linewidth = 2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "lda_y_pred = lda_fit.predict(X_test)\n",
        "lda_auc_score = roc_auc_score(y_test, lda_y_pred)\n",
        "print(f\"The area under the ROC Curve, using LDA is: {lda_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quadratic Discriminant Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### QDA: model calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "qda = QuadraticDiscriminantAnalysis()\n",
        "qda_fit = qda.fit(X_train, y_train)\n",
        "\n",
        "predxclass = qda.predict(X_test)\n",
        "pY_test = qda_fit.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### QDA: evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "qda_accuracy = accuracy_score(y_test, predxclass)\n",
        "qda_precision = precision_score(y_test, predxclass)\n",
        "qda_recall = recall_score(y_test, predxclass)\n",
        "qda_f1_score = f1_score(y_test, predxclass)\n",
        "\n",
        "print(f\"Accuracy using QDA is: {qda_accuracy:.3f}\")\n",
        "print(f\"Precision using QDA is: {qda_precision:.3f}\")\n",
        "print(f\"Recall using QDA is: {qda_recall:.3f}\")\n",
        "print(f\"F1-score using QDA is: {qda_f1_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### QDA: ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "qda_y_prob_1 = pY_test[:, 1]\n",
        "qda_FPR, qda_TPR, qda_threshold = roc_curve(y_test, qda_y_prob_1)\n",
        "\n",
        "figure = plt.figure(figsize=(4,2))\n",
        "plt.plot(qda_FPR, qda_TPR, linewidth=2)\n",
        "plt.title('Quadratic Discriminant Analysis. ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(qda_TPR, qda_TPR, \"k--\", linewidth = 2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "qda_y_pred = qda_fit.predict(X_test)\n",
        "qda_auc_score = roc_auc_score(y_test, qda_y_pred)\n",
        "print(f\"The area under the ROC Curve, using QDA is: {qda_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logistic Regression: model calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating and fitting the logistic regression model\n",
        "LR = LogisticRegression()\n",
        "lr_fit = LR.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test set\n",
        "predxclass = LR.predict(X_test)\n",
        "pY_test = lr_fit.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logistic Regression: evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_accuracy = accuracy_score(y_test, predxclass)\n",
        "lr_precision = precision_score(y_test, predxclass)\n",
        "lr_recall = recall_score(y_test, predxclass)\n",
        "lr_f1_score = f1_score(y_test, predxclass)\n",
        "\n",
        "print(f\"Accuracy using LR is: {lr_accuracy:.3f}\")\n",
        "print(f\"Precision using LR is: {lr_precision:.3f}\")\n",
        "print(f\"Recall using LR is: {lr_recall:.3f}\")\n",
        "print(f\"F1-score using LR is: {lr_f1_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logistic Regression: ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_y_prob_1 = pY_test[:, 1]\n",
        "lr_FPR, lr_TPR, lr_threshold = roc_curve(y_test, lr_y_prob_1)\n",
        "\n",
        "figure = plt.figure(figsize=(4,2))\n",
        "plt.plot(lr_FPR, lr_TPR, linewidth=2)\n",
        "plt.title('Logistic Regression. ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(lr_TPR, lr_TPR, \"k--\", linewidth = 2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "lr_y_pred = lr_fit.predict(X_test)\n",
        "lr_auc_score = roc_auc_score(y_test, lr_y_pred)\n",
        "print(f\"The area under the ROC Curve, using LR is: {lr_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwiKPnV6EjSD"
      },
      "source": [
        "## Classification Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From here on, the pipeline for the evaluation of the model gets more complicated: for Naive Bayes, LDA and QDA, applying the knowledge from the lectures, we reasoned that there were not hyperparameters to estimate via CV.\n",
        "\n",
        "Sadly, this is not the case for Classification Decision Tree, Bagging and Random Forest: we are going to tune the main hyperparameters via 10-fold CV picking the optimal parameter from a grid of values we deem feasible for this problem, thus from now on we are going to add a section \"parameter estimation\" to each section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj6IqDv5xBQH"
      },
      "source": [
        "### Decision Tree: parameter estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiNVsstbEqiz"
      },
      "outputs": [],
      "source": [
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 3, 4],\n",
        "    'min_samples_leaf': [1, 2, 3],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=tree, param_grid=param_grid, cv=10, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "max_depth_cv = grid_search.best_params_['max_depth']\n",
        "print(f\"The optimal value for the hyperparameter max depth is: {max_depth_cv}\")\n",
        "min_samples_leaf_cv = grid_search.best_params_['min_samples_leaf']\n",
        "print(f\"The optimal value for the hyperparameter min samples leaf is: {min_samples_leaf_cv}\")\n",
        "min_samples_split_cv = grid_search.best_params_['min_samples_split']\n",
        "print(f\"The optimal value for the hyperparameter min samples split is: {min_samples_split_cv}\")\n",
        "max_features_cv = grid_search.best_params_['max_features']\n",
        "print(f\"The optimal value for the hyperparameter max features is: {max_features_cv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an64cHvTlyHB"
      },
      "source": [
        "### Decision Tree: model calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYQxF21PmIAd"
      },
      "outputs": [],
      "source": [
        "tree = DecisionTreeClassifier(max_depth = max_depth_cv, min_samples_leaf=min_samples_leaf_cv,\n",
        "                              min_samples_split=min_samples_split_cv, max_features=max_features_cv)\n",
        "treefit = tree.fit(X_train, y_train)\n",
        "\n",
        "pY_test=treefit.predict_proba(X_test)\n",
        "predxclass=np.argmax(pY_test,axis=1)\n",
        "print(predxclass)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwQv8ebQoF7U"
      },
      "source": [
        "### Decision Tree: evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG7TzaTooIWt"
      },
      "outputs": [],
      "source": [
        "dt_accuracy = accuracy_score(y_test, predxclass)\n",
        "dt_precision = precision_score(y_test, predxclass)\n",
        "dt_recall = recall_score(y_test, predxclass)\n",
        "dt_f1_score = f1_score(y_test, predxclass)\n",
        "dt_E_test = (y_test != predxclass).sum()/len(y_test)\n",
        "\n",
        "print(f\"Accuracy using Classification DT: {dt_accuracy:.3f}\")\n",
        "print(f\"Precision using Classification DT: {dt_precision:.3f}\")\n",
        "print(f\"Recall using Classification DT: {dt_recall:.3f}\")\n",
        "print(f\"F1-score using Classification DT: {dt_f1_score:.3f}\")\n",
        "print(f\"Error in the testing set using Classification DT: {dt_E_test:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McVNwIrXs8wh"
      },
      "source": [
        "Let us explore visually the structure of the tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOgMPta6tCJO"
      },
      "outputs": [],
      "source": [
        "r = export_text(treefit)\n",
        "print(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For a cleaner visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve the names of the features\n",
        "f_names = ['sbp','tobacco','ldl','adiposity','typea','obesity','alcohol','age']\n",
        "c_names = ['0','1']\n",
        "\n",
        "# Visualize the decision tree\n",
        "plt.figure(figsize=(15, 10))\n",
        "plot_tree(tree, feature_names=f_names, class_names=c_names, filled=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decision Tree: ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tree_y_prob_1 = pY_test[:, 1]\n",
        "tree_FPR, tree_TPR, tree_threshold = roc_curve(y_test, tree_y_prob_1)\n",
        "\n",
        "figure = plt.figure(figsize=(4,2))\n",
        "plt.plot(tree_FPR, tree_TPR, linewidth=2)\n",
        "plt.title('Decision Tree ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(tree_TPR, tree_TPR, \"k--\", linewidth = 2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "tree_y_pred = treefit.predict(X_test)\n",
        "tree_auc_score = roc_auc_score(y_test, tree_y_pred)\n",
        "print(f\"The area under the ROC Curve, using Classification Decision Tree is: {tree_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDWsA-QsPpkH"
      },
      "source": [
        "## Bagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bagging: parameters estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-2cIUKHPucg"
      },
      "outputs": [],
      "source": [
        "treebag = DecisionTreeClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_samples':[0.8, 1.0],\n",
        "    'max_features': ['sqrt', 'log2', 2, 3, 4]\n",
        "}\n",
        "\n",
        "bagging = BaggingClassifier(estimator=treebag)\n",
        "grid_search = GridSearchCV(bagging, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)\n",
        "\n",
        "n_estimators_cv = grid_search.best_params_['n_estimators']\n",
        "print(f\"The optimal value for the hyperparameter n estimators is: {n_estimators_cv}\")\n",
        "max_features_cv = grid_search.best_params_['max_features']\n",
        "print(f\"The optimal value for the hyperparameter max features is: {max_features_cv}\")\n",
        "max_samples_cv = grid_search.best_params_['max_samples']\n",
        "print(f\"The optimal value for the hyperparameter max samples is: {max_samples_cv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bagging: model calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bagmod=BaggingClassifier(n_estimators=n_estimators_cv, max_features=max_features_cv, max_samples=max_samples_cv)\n",
        "\n",
        "treemodfit=treebag.fit(X_train, y_train)\n",
        "bagmodfit=bagmod.fit(X_train, y_train)\n",
        "pY_test=bagmodfit.predict_proba(X_test)\n",
        "predxclass=np.argmax(pY_test,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bagging: evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bag_accuracy = accuracy_score(y_test, predxclass)\n",
        "bag_precision = precision_score(y_test, predxclass)\n",
        "bag_recall = recall_score(y_test, predxclass)\n",
        "bag_f1_score = f1_score(y_test, predxclass)\n",
        "bag_E_test = (y_test != predxclass).sum() / len(y_test)\n",
        "\n",
        "print(f\"Accuracy using Bagging is: {bag_accuracy:.3f}\")\n",
        "print(f\"Precision using Bagging is: {bag_precision:.3f}\")\n",
        "print(f\"Recall using Bagging is: {bag_recall:.3f}\")\n",
        "print(f\"F1-score using Bagging is: {bag_f1_score:.3f}\")\n",
        "print(f\"Error in the testing set using Bagging: {bag_E_test:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bagging: ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bag_y_prob_1 = bagmodfit.predict_proba(X_test)[:, 1]\n",
        "bag_FPR, bag_TPR, bag_threshold = roc_curve(y_test, bag_y_prob_1)\n",
        "\n",
        "figure=plt.figure(figsize=(4,2))\n",
        "plt.plot(bag_FPR, bag_TPR, linewidth=2)\n",
        "plt.title('Bagging ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(bag_TPR, bag_TPR, \"k--\", linewidth=2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "bag_y_pred = bagmodfit.predict(X_test)\n",
        "bag_auc_score = roc_auc_score(y_test, bag_y_pred)\n",
        "print(f\"The area under the ROC Curve, using Bagging, is: {bag_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZN1YSRPPvQk"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RF: parameters estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRIiNEBeP4vI"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators':[50, 100, 150],  \n",
        "    'max_depth':[3, 5, None], \n",
        "    'min_samples_split':[2, 3, 5],\n",
        "    'min_samples_leaf':[1, 2, 3],\n",
        "    'max_features': ['sqrt', 'log2', 2, 3, 4]\n",
        "}\n",
        "#RF = RandomForestClassifier(max_depth=max_depth_cv, random_state=0, oob_score = True, max_features='sqrt', )\n",
        "RF = RandomForestClassifier()\n",
        "grid_search = GridSearchCV(RF, param_grid, cv = 5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "n_estimators_cv = grid_search.best_params_['n_estimators']\n",
        "print(f\"The optimal value for the hyperparameter n estimators is: {n_estimators_cv}\")\n",
        "max_depth_cv = grid_search.best_params_['max_depth']\n",
        "print(f\"The optimal value for the hyperparameter max depth is: {max_depth_cv}\")\n",
        "min_samples_split_cv = grid_search.best_params_['min_samples_split']\n",
        "print(f\"The optimal value for the hyperparameter min samples split is: {min_samples_split_cv}\")\n",
        "min_samples_leaf_cv = grid_search.best_params_['min_samples_leaf']\n",
        "print(f\"The optimal value for the hyperparameter min samples leaf is: {min_samples_leaf_cv}\")\n",
        "max_features_cv = grid_search.best_params_['max_features']\n",
        "print(f\"The optimal value for the hyperparameter max features is: {max_features_cv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RF: model calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RF = RandomForestClassifier(max_depth=max_depth_cv, oob_score = True, max_features=max_features_cv, n_estimators=n_estimators_cv, min_samples_leaf=min_samples_leaf_cv, min_samples_split=min_samples_split_cv)\n",
        "\n",
        "RFfit = RF.fit(X_train, y_train)\n",
        "pY_test=RFfit.predict_proba(X_test)\n",
        "predxclass=np.argmax(pY_test,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RF: evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_accuracy = accuracy_score(y_test, predxclass)\n",
        "rf_precision = precision_score(y_test, predxclass)\n",
        "rf_recall = recall_score(y_test, predxclass)\n",
        "rf_f1_score = f1_score(y_test, predxclass)\n",
        "rf_E_test = (y_test != predxclass).sum() / len(y_test)\n",
        "OOB=RF.oob_score_\n",
        "\n",
        "print(f\"Accuracy using RF is: {rf_accuracy:.3f}\")\n",
        "print(f\"Precision using RF is: {rf_precision:.3f}\")\n",
        "print(f\"Recall using RF is: {rf_recall:.3f}\")\n",
        "print(f\"F1-score using RF is: {rf_f1_score:.3f}\")\n",
        "print(f\"Error in the testing set using RF: {bag_E_test:.3f}\")\n",
        "print(f\"The Out Of the Bag error is: {OOB:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RF: ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_y_prob_1 = RFfit.predict_proba(X_test)[:, 1]\n",
        "\n",
        "rf_FPR, rf_TPR, rf_threshold = roc_curve(y_test, rf_y_prob_1)\n",
        "\n",
        "figure = plt.figure(figsize=(4, 2))\n",
        "plt.plot(rf_FPR, rf_TPR, linewidth = 2)\n",
        "plt.title('Random Forest ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(rf_TPR, rf_TPR, \"--k\", linewidth=2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "rf_y_pred = RFfit.predict(X_test)\n",
        "rf_auc_score = roc_auc_score(y_test, rf_y_pred)\n",
        "print(f\"The area under the ROC Curve, using Random Forest, is: {rf_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### VIM analysis\n",
        "Due to the random selection of the features done by the model, only a restricted number of them has been included in the trees. Therefore, the latter may be problematic if there is one (or more) features that reduce heterogeneity in a greater way than the others. Indeed, not including the variable in the tree will create a meaningless tree (or a tree that does not represent much). At the end, we have decided to include a part where we analyze at the VIM to make sure to that it is at least approximatively balanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieve feature importances\n",
        "importances = RF.feature_importances_\n",
        "\n",
        "# Sort feature importances in descending order\n",
        "indices = importances.argsort()[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "for f in range(X.shape[1]):\n",
        "    print(f\"{f + 1}. Feature {indices[f]}: {importances[indices[f]]:.3f}\")\n",
        "\n",
        "plt.figure()\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.bar(range(X_train.shape[1]), importances[indices], color='b', align='center')\n",
        "plt.xticks(range((X_train.shape[1])), indices)\n",
        "plt.xlim([-1, X_train.shape[1]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From our theoretical knowledge we know that Random Forest is going to work well as a classification method only if the VIM is balanced; otherwise we are going to get poor performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Adaboost "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AB: parameters estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 0.5]\n",
        "}\n",
        "ab = AdaBoostClassifier()\n",
        "grid_search = GridSearchCV(ab, param_grid, cv = 10)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "n_estimators_cv = grid_search.best_params_['n_estimators']\n",
        "print(f\"The optimal value for the hyperparameter n estimators is: {n_estimators_cv}\")\n",
        "learning_rate_cv = grid_search.best_params_['learning_rate']\n",
        "print(f\"The optimal value for the hyperparameter learning rate is: {learning_rate_cv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AB: Model calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ab = AdaBoostClassifier(n_estimators=n_estimators_cv, learning_rate=learning_rate_cv)\n",
        "ab_fit = ab.fit(X_train, y_train)\n",
        "pY_test = ab_fit.predict_proba(X_test)\n",
        "predxclass = np.argmax(pY_test, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AB: evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ab_accuracy = accuracy_score(y_test, predxclass)\n",
        "ab_precision = precision_score(y_test, predxclass)\n",
        "ab_recall = recall_score(y_test, predxclass)\n",
        "ab_f1_score = f1_score(y_test, predxclass)\n",
        "\n",
        "print(f\"Accuracy using AB is: {ab_accuracy:.3f}\")\n",
        "print(f\"Precision using AB is: {ab_precision:.3f}\")\n",
        "print(f\"Recall using AB is: {ab_recall:.3f}\")\n",
        "print(f\"F1-score using AB is: {ab_f1_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AB: ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ab_y_prob_1 = ab_fit.predict_proba(X_test)[:, 1]\n",
        "\n",
        "ab_FPR, ab_TPR, ab_threshold = roc_curve(y_test, ab_y_prob_1)\n",
        "\n",
        "figure = plt.figure(figsize=(4, 2))\n",
        "plt.plot(ab_FPR, ab_TPR, linewidth = 2)\n",
        "plt.title('Adaboost ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(ab_TPR, ab_TPR, \"--k\", linewidth=2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "ab_y_pred = ab_fit.predict(X_test)\n",
        "ab_auc_score = roc_auc_score(y_test, ab_y_pred)\n",
        "print(f\"The area under the ROC Curve, using Adaboost, is: {ab_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AB: Underlying Tree Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "ab_staged = ab.staged_predict(X_train)\n",
        "\n",
        "ab_seq_errors = []\n",
        "for predxclass in ab_staged:\n",
        "    ab_seq_errors.append(metrics.accuracy_score(y_train, predxclass))\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(ab_seq_errors)\n",
        "plt.title('Adaboost Tree Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of Trees')\n",
        "plt.ylim(0.6, 0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gradient Boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GB: parameters estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "gb = GradientBoostingClassifier()\n",
        "param_grid = {\n",
        "    'loss': ['log_loss', 'deviance', 'exponential'],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.7, 0.8, 1.0],\n",
        "    'min_samples_split':[2, 3]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(gb, param_grid, cv = 5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "loss_cv = grid_search.best_params_['loss']\n",
        "print(f\"The optimal value for the hyperparameter loss is: {loss_cv}\")\n",
        "n_estimators_cv = grid_search.best_params_['n_estimators']\n",
        "print(f\"The optimal value for the hyperparameter n estimators is: {n_estimators_cv}\")\n",
        "max_depth_cv = grid_search.best_params_['max_depth']\n",
        "print(f\"The optimal value for the hyperparameter max depth is: {max_depth_cv}\")\n",
        "subsample_cv = grid_search.best_params_['subsample']\n",
        "print(f\"The optimal value for the hyperparameter subsample is: {subsample_cv}\")\n",
        "min_samples_split_cv = grid_search.best_params_['min_samples_split']\n",
        "print(f\"The optimal value for the hyperparameter min samples split is: {min_samples_split_cv}\")\n",
        "learning_rate_cv = grid_search.best_params_['learning_rate']\n",
        "print(f\"The optimal value for the hyperparameter learning rate is: {learning_rate_cv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GB: model calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gb = GradientBoostingClassifier(loss=loss_cv, n_estimators=n_estimators_cv, max_depth=max_depth_cv,\n",
        "                                subsample=subsample_cv, min_samples_split=min_samples_split_cv, learning_rate=learning_rate_cv)\n",
        "\n",
        "gb_fit = gb.fit(X_train, y_train)\n",
        "pY_test = gb_fit.predict_proba(X_test)\n",
        "predxclass = np.argmax(pY_test, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GB: evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gb_accuracy = accuracy_score(y_test, predxclass)\n",
        "gb_precision = precision_score(y_test, predxclass)\n",
        "gb_recall = recall_score(y_test, predxclass)\n",
        "gb_f1_score = f1_score(y_test, predxclass)\n",
        "\n",
        "print(f\"Accuracy using GB is: {gb_accuracy:.3f}\")\n",
        "print(f\"Precision using GB is: {gb_precision:.3f}\")\n",
        "print(f\"Recall using GB is: {gb_recall:.3f}\")\n",
        "print(f\"F1-score using GB is: {gb_f1_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GB: ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gb_y_prob_1 = gb_fit.predict_proba(X_test)[:, 1]\n",
        "\n",
        "gb_FPR, gb_TPR, gb_threshold = roc_curve(y_test, gb_y_prob_1)\n",
        "\n",
        "figure = plt.figure(figsize=(4, 2))\n",
        "plt.plot(gb_FPR, gb_TPR, linewidth = 2)\n",
        "plt.title('Gradient Boosting ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(gb_TPR, gb_TPR, \"--k\", linewidth=2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "gb_y_pred = gb_fit.predict(X_test)\n",
        "gb_auc_score = roc_auc_score(y_test, gb_y_pred)\n",
        "print(f\"The area under the ROC Curve, using Gradient Boosting, is: {gb_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GB: Underlying Tree Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "gb_staged = gb_fit.staged_predict(X_train)\n",
        "\n",
        "gb_seq_errors = []\n",
        "for predxclass in gb_staged:\n",
        "    gb_seq_errors.append(metrics.accuracy_score(y_train, predxclass))\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(gb_seq_errors)\n",
        "plt.title('Gradient Boosting Tree Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of Trees')\n",
        "plt.ylim(0.6, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking: parameters estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "stk_estimators = [\n",
        "    ('nb', nb),\n",
        "    ('lda', lda),\n",
        "    ('qda', qda),\n",
        "    ('lr', LR),\n",
        "    ('dt', tree)\n",
        "]\n",
        "\n",
        "stk_nb = StackingClassifier(estimators=stk_estimators, final_estimator=nb)\n",
        "stk_nb_fit = stk_nb.fit(X_train, y_train)\n",
        "pY_test = stk_nb_fit.predict_proba(X_test)\n",
        "predxclass = np.argmax(pY_test, axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, NB: Evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stknb_accuracy = accuracy_score(y_test, predxclass)\n",
        "stknb_precision = precision_score(y_test, predxclass)\n",
        "stknb_recall = recall_score(y_test, predxclass)\n",
        "stknb_f1_score = f1_score(y_test, predxclass)\n",
        "\n",
        "print(f\"Accuracy using Stacking is: {stknb_accuracy:.3f}\")\n",
        "print(f\"Precision using Stacking is: {stknb_precision:.3f}\")\n",
        "print(f\"Recall using Stacking is: {stknb_recall:.3f}\")\n",
        "print(f\"F1-score using Stacking is: {stknb_f1_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, NB: ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stk_y_prob_1 = stk_nb_fit.predict_proba(X_test)[:, 1]\n",
        "\n",
        "stk_FPR, stk_TPR, stk_threshold = roc_curve(y_test, stk_y_prob_1)\n",
        "\n",
        "figure = plt.figure(figsize=(4, 2))\n",
        "plt.plot(stk_FPR, stk_TPR, linewidth = 2)\n",
        "plt.title('Stacking (NB) ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(stk_TPR, stk_TPR, \"--k\", linewidth=2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "stk_y_pred = stk_nb_fit.predict(X_test)\n",
        "stk_auc_score = roc_auc_score(y_test, stk_y_pred)\n",
        "print(f\"The area under the ROC Curve, using Stacking (NB), is: {stk_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, LDA: model calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stk_lda = StackingClassifier(estimators=stk_estimators, final_estimator=lda)\n",
        "stk_lda_fit = stk_lda.fit(X_train, y_train)\n",
        "pY_test = stk_lda_fit.predict_proba(X_test)\n",
        "predxclass = np.argmax(pY_test, axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, LDA: evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stklda_accuracy = accuracy_score(y_test, predxclass)\n",
        "stklda_precision = precision_score(y_test, predxclass)\n",
        "stklda_recall = recall_score(y_test, predxclass)\n",
        "stklda_f1_score = f1_score(y_test, predxclass)\n",
        "\n",
        "print(f\"Accuracy using Stacking is: {stklda_accuracy:.3f}\")\n",
        "print(f\"Precision using Stacking is: {stklda_precision:.3f}\")\n",
        "print(f\"Recall using Stacking is: {stklda_recall:.3f}\")\n",
        "print(f\"F1-score using Stacking is: {stklda_f1_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, LDA: ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stk_y_prob_1 = stk_lda_fit.predict_proba(X_test)[:, 1]\n",
        "\n",
        "stk_FPR, stk_TPR, stk_threshold = roc_curve(y_test, stk_y_prob_1)\n",
        "\n",
        "figure = plt.figure(figsize=(4, 2))\n",
        "plt.plot(stk_FPR, stk_TPR, linewidth = 2)\n",
        "plt.title('Stacking (LDA) ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(stk_TPR, stk_TPR, \"--k\", linewidth=2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "stk_y_pred = stk_lda_fit.predict(X_test)\n",
        "stk_auc_score = roc_auc_score(y_test, stk_y_pred)\n",
        "print(f\"The area under the ROC Curve, using Stacking (LDA), is: {stk_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, QDA: model calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stk_qda = StackingClassifier(estimators=stk_estimators, final_estimator=qda)\n",
        "stk_qda_fit = stk_qda.fit(X_train, y_train)\n",
        "pY_test = stk_qda_fit.predict_proba(X_test)\n",
        "predxclass = np.argmax(pY_test, axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, QDA: evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stkqda_accuracy = accuracy_score(y_test, predxclass)\n",
        "stkqda_precision = precision_score(y_test, predxclass)\n",
        "stkqda_recall = recall_score(y_test, predxclass)\n",
        "stkqda_f1_score = f1_score(y_test, predxclass)\n",
        "\n",
        "print(f\"Accuracy using Stacking is: {stkqda_accuracy:.3f}\")\n",
        "print(f\"Precision using Stacking is: {stkqda_precision:.3f}\")\n",
        "print(f\"Recall using Stacking is: {stkqda_recall:.3f}\")\n",
        "print(f\"F1-score using Stacking is: {stkqda_f1_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, QDA: ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stk_y_prob_1 = stk_lda_fit.predict_proba(X_test)[:, 1]\n",
        "\n",
        "stk_FPR, stk_TPR, stk_threshold = roc_curve(y_test, stk_y_prob_1)\n",
        "\n",
        "figure = plt.figure(figsize=(4, 2))\n",
        "plt.plot(stk_FPR, stk_TPR, linewidth = 2)\n",
        "plt.title('Stacking (QDA) ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(stk_TPR, stk_TPR, \"--k\", linewidth=2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "stk_y_pred = stk_qda_fit.predict(X_test)\n",
        "stk_auc_score = roc_auc_score(y_test, stk_y_pred)\n",
        "print(f\"The area under the ROC Curve, using Stacking (QDA), is: {stk_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, LR: model calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stk_lr = StackingClassifier(estimators=stk_estimators, final_estimator=LR)\n",
        "stk_lr_fit = stk_lr.fit(X_train, y_train)\n",
        "pY_test = stk_lr_fit.predict_proba(X_test)\n",
        "predxclass = np.argmax(pY_test, axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, LR: evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stklr_accuracy = accuracy_score(y_test, predxclass)\n",
        "stklr_precision = precision_score(y_test, predxclass)\n",
        "stklr_recall = recall_score(y_test, predxclass)\n",
        "stklr_f1_score = f1_score(y_test, predxclass)\n",
        "\n",
        "print(f\"Accuracy using Stacking is: {stklr_accuracy:.3f}\")\n",
        "print(f\"Precision using Stacking is: {stklr_precision:.3f}\")\n",
        "print(f\"Recall using Stacking is: {stklr_recall:.3f}\")\n",
        "print(f\"F1-score using Stacking is: {stklr_f1_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, LR: ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stk_y_prob_1 = stk_lda_fit.predict_proba(X_test)[:, 1]\n",
        "\n",
        "stk_FPR, stk_TPR, stk_threshold = roc_curve(y_test, stk_y_prob_1)\n",
        "\n",
        "figure = plt.figure(figsize=(4, 2))\n",
        "plt.plot(stk_FPR, stk_TPR, linewidth = 2)\n",
        "plt.title('Stacking (LR) ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(stk_TPR, stk_TPR, \"--k\", linewidth=2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "stk_y_pred = stk_lr_fit.predict(X_test)\n",
        "stk_auc_score = roc_auc_score(y_test, stk_y_pred)\n",
        "print(f\"The area under the ROC Curve, using Stacking (LR), is: {stk_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, DT: model calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stk_dt = StackingClassifier(estimators=stk_estimators, final_estimator=tree)\n",
        "stk_dt_fit = stk_dt.fit(X_train, y_train)\n",
        "pY_test = stk_dt_fit.predict_proba(X_test)\n",
        "predxclass = np.argmax(pY_test, axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, DT: evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stkdt_accuracy = accuracy_score(y_test, predxclass)\n",
        "stkdt_precision = precision_score(y_test, predxclass)\n",
        "stkdt_recall = recall_score(y_test, predxclass)\n",
        "stkdt_f1_score = f1_score(y_test, predxclass)\n",
        "\n",
        "print(f\"Accuracy using Stacking is: {stkdt_accuracy:.3f}\")\n",
        "print(f\"Precision using Stacking is: {stkdt_precision:.3f}\")\n",
        "print(f\"Recall using Stacking is: {stkdt_recall:.3f}\")\n",
        "print(f\"F1-score using Stacking is: {stkdt_f1_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stacking, DT: ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stk_y_prob_1 = stk_lda_fit.predict_proba(X_test)[:, 1]\n",
        "\n",
        "stk_FPR, stk_TPR, stk_threshold = roc_curve(y_test, stk_y_prob_1)\n",
        "\n",
        "figure = plt.figure(figsize=(4, 2))\n",
        "plt.plot(stk_FPR, stk_TPR, linewidth = 2)\n",
        "plt.title('Stacking (DT) ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.plot(stk_TPR, stk_TPR, \"--k\", linewidth=2)\n",
        "plt.grid(linestyle='dashed')\n",
        "plt.show()\n",
        "\n",
        "stk_y_pred = stk_dt_fit.predict(X_test)\n",
        "stk_auc_score = roc_auc_score(y_test, stk_y_pred)\n",
        "print(f\"The area under the ROC Curve, using Stacking (DT), is: {stk_auc_score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation of our results\n",
        "\n",
        "To deliver a cleaner exposition of our work, in this notebook we present the various models once with a single splitting of the dataset.\n",
        "\n",
        "Now, to give robustness to our results, we create a for cycle that repeats the same procedure for 4 more random splittings of the dataset; we are going to collect the values of the main metrics, compute the average and display them in the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy using nb is: 0.710\n",
            "Precision using nb is: 0.559\n",
            "Recall using nb is: 0.579\n",
            "F1-score using nb is: 0.568\n",
            " \n",
            "Accuracy using lda is: 0.738\n",
            "Precision using lda is: 0.631\n",
            "Recall using lda is: 0.501\n",
            "F1-score using lda is: 0.556\n",
            " \n",
            "Accuracy using qda is: 0.708\n",
            "Precision using qda is: 0.583\n",
            "Recall using qda is: 0.468\n",
            "F1-score using qda is: 0.517\n",
            " \n",
            "Accuracy using lr is: 0.735\n",
            "Precision using lr is: 0.619\n",
            "Recall using lr is: 0.521\n",
            "F1-score using lr is: 0.565\n",
            " \n",
            "Accuracy using cdt is: 0.710\n",
            "Precision using cdt is: 0.611\n",
            "Recall using cdt is: 0.428\n",
            "F1-score using cdt is: 0.487\n",
            " \n",
            "Accuracy using bag is: 0.701\n",
            "Precision using bag is: 0.567\n",
            "Recall using bag is: 0.383\n",
            "F1-score using bag is: 0.447\n",
            " \n",
            "Accuracy using rf is: 0.703\n",
            "Precision using rf is: 0.587\n",
            "Recall using rf is: 0.356\n",
            "F1-score using rf is: 0.443\n",
            " \n",
            "Accuracy using ab is: 0.757\n",
            "Precision using ab is: 0.706\n",
            "Recall using ab is: 0.477\n",
            "F1-score using ab is: 0.563\n",
            " \n",
            "Accuracy using gb is: 0.710\n",
            "Precision using gb is: 0.605\n",
            "Recall using gb is: 0.445\n",
            "F1-score using gb is: 0.502\n",
            " \n",
            "Accuracy using stk is: 0.723\n",
            "Precision using stk is: 0.598\n",
            "Recall using stk is: 0.525\n",
            "F1-score using stk is: 0.550\n",
            "[0.83870968 0.69892473 0.69892473 0.75268817 0.68817204 0.76344086\n",
            " 0.69892473 0.67741935 0.69892473 0.70967742 0.8172043  0.6344086\n",
            " 0.68817204 0.72043011 0.76344086 0.77419355 0.72043011 0.68817204\n",
            " 0.75268817 0.72043011 0.77419355 0.67741935 0.66666667 0.72043011\n",
            " 0.74193548]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "k = 5\n",
        "\n",
        "nb_accurancy_test_k = np.zeros(k)\n",
        "nb_precision_test_k = np.zeros(k)\n",
        "nb_recall_test_k = np.zeros(k)\n",
        "nb_F1_score_test_k = np.zeros(k)\n",
        "nb_accurancy_test_k[0] = nb_accuracy\n",
        "nb_precision_test_k[0] = nb_precision\n",
        "nb_recall_test_k[0] = nb_recall\n",
        "nb_F1_score_test_k[0] = nb_f1_score\n",
        "\n",
        "lda_accurancy_test_k = np.zeros(k)\n",
        "lda_precision_test_k = np.zeros(k)\n",
        "lda_recall_test_k = np.zeros(k)\n",
        "lda_F1_score_test_k = np.zeros(k)\n",
        "lda_accurancy_test_k[0] = lda_accuracy\n",
        "lda_precision_test_k[0] = lda_precision\n",
        "lda_recall_test_k[0] = lda_recall\n",
        "lda_F1_score_test_k[0] = lda_f1_score\n",
        "\n",
        "qda_accurancy_test_k = np.zeros(k)\n",
        "qda_precision_test_k = np.zeros(k)\n",
        "qda_recall_test_k = np.zeros(k)\n",
        "qda_F1_score_test_k = np.zeros(k)\n",
        "qda_accurancy_test_k[0] = qda_accuracy\n",
        "qda_precision_test_k[0] = qda_precision\n",
        "qda_recall_test_k[0] = qda_recall\n",
        "qda_F1_score_test_k[0] = qda_f1_score\n",
        "\n",
        "lr_accurancy_test_k = np.zeros(k)\n",
        "lr_precision_test_k = np.zeros(k)\n",
        "lr_recall_test_k = np.zeros(k)\n",
        "lr_F1_score_test_k = np.zeros(k)\n",
        "lr_accurancy_test_k[0] = lr_accuracy\n",
        "lr_precision_test_k[0] = lr_precision\n",
        "lr_recall_test_k[0] = lr_recall\n",
        "lr_F1_score_test_k[0] = lr_f1_score\n",
        "\n",
        "cdt_accurancy_test_k = np.zeros(k)\n",
        "cdt_precision_test_k = np.zeros(k)\n",
        "cdt_recall_test_k = np.zeros(k)\n",
        "cdt_F1_score_test_k = np.zeros(k)\n",
        "cdt_accurancy_test_k[0] = dt_accuracy\n",
        "cdt_precision_test_k[0] = dt_precision\n",
        "cdt_recall_test_k[0] = dt_recall\n",
        "cdt_F1_score_test_k[0] = dt_f1_score\n",
        "\n",
        "bag_accurancy_test_k = np.zeros(k)\n",
        "bag_precision_test_k = np.zeros(k)\n",
        "bag_recall_test_k = np.zeros(k)\n",
        "bag_F1_score_test_k = np.zeros(k)\n",
        "bag_accurancy_test_k[0] = bag_accuracy\n",
        "bag_precision_test_k[0] = bag_precision\n",
        "bag_recall_test_k[0] = bag_recall\n",
        "bag_F1_score_test_k[0] = bag_f1_score\n",
        "\n",
        "rf_accurancy_test_k = np.zeros(k)\n",
        "rf_precision_test_k = np.zeros(k)\n",
        "rf_recall_test_k = np.zeros(k)\n",
        "rf_F1_score_test_k = np.zeros(k)\n",
        "rf_accurancy_test_k[0] = rf_accuracy\n",
        "rf_precision_test_k[0] = rf_precision\n",
        "rf_recall_test_k[0] = rf_recall\n",
        "rf_F1_score_test_k[0] = rf_f1_score\n",
        "\n",
        "ab_accurancy_test_k = np.zeros(k)\n",
        "ab_precision_test_k = np.zeros(k)\n",
        "ab_recall_test_k = np.zeros(k)\n",
        "ab_F1_score_test_k = np.zeros(k)\n",
        "ab_accurancy_test_k[0] = ab_accuracy\n",
        "ab_precision_test_k[0] = ab_precision\n",
        "ab_recall_test_k[0] = ab_recall\n",
        "ab_F1_score_test_k[0] = ab_f1_score\n",
        "\n",
        "gb_accurancy_test_k = np.zeros(k)\n",
        "gb_precision_test_k = np.zeros(k)\n",
        "gb_recall_test_k = np.zeros(k)\n",
        "gb_F1_score_test_k = np.zeros(k)\n",
        "gb_accurancy_test_k[0] = gb_accuracy\n",
        "gb_precision_test_k[0] = gb_precision\n",
        "gb_recall_test_k[0] = gb_recall\n",
        "gb_F1_score_test_k[0] = gb_f1_score\n",
        "\n",
        "stk_accurancy_test_k = np.zeros(5*k)\n",
        "stk_precision_test_k = np.zeros(5*k)\n",
        "stk_recall_test_k = np.zeros(5*k)\n",
        "stk_F1_score_test_k = np.zeros(5*k)\n",
        "stk_accurancy_test_k[0] = stknb_accuracy\n",
        "stk_accurancy_test_k[5] = stklda_accuracy\n",
        "stk_accurancy_test_k[10] = stkqda_accuracy\n",
        "stk_accurancy_test_k[15] = stklr_accuracy\n",
        "stk_accurancy_test_k[20] = stkdt_accuracy\n",
        "stk_precision_test_k[0] = stknb_precision\n",
        "stk_precision_test_k[5] = stklda_precision\n",
        "stk_precision_test_k[10] = stkqda_precision\n",
        "stk_precision_test_k[15] = stklr_precision\n",
        "stk_precision_test_k[20] = stkdt_precision\n",
        "stk_recall_test_k[0] = stknb_recall\n",
        "stk_recall_test_k[5] = stklda_recall\n",
        "stk_recall_test_k[10] = stkqda_recall\n",
        "stk_recall_test_k[15] = stklr_recall\n",
        "stk_recall_test_k[20] = stkdt_recall\n",
        "stk_F1_score_test_k[0] = stknb_f1_score\n",
        "stk_F1_score_test_k[5] = stklda_f1_score\n",
        "stk_F1_score_test_k[10] = stkqda_f1_score\n",
        "stk_F1_score_test_k[15] = stklr_f1_score\n",
        "stk_F1_score_test_k[20] = stkdt_f1_score\n",
        "\n",
        "for i in range(1,k):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "    nb = GaussianNB()\n",
        "    nb_fit = nb.fit(X_train, y_train)\n",
        "    pY_test=nb_fit.predict_proba(X_test)\n",
        "    predxclass=np.argmax(pY_test,axis=1)\n",
        "    nb_accurancy_test_k[i] = accuracy_score(y_test, predxclass) #same thing written before\n",
        "    nb_precision_test_k[i] = precision_score(y_test, predxclass)\n",
        "    nb_recall_test_k[i] = recall_score(y_test, predxclass)\n",
        "    nb_F1_score_test_k[i] = f1_score(y_test, predxclass)\n",
        "\n",
        "    lda = LinearDiscriminantAnalysis()\n",
        "    lda_fit = lda.fit(X_train, y_train)\n",
        "    predxclass = lda.predict(X_test)\n",
        "    lda_accurancy_test_k[i] = accuracy_score(y_test, predxclass) #same thing written before\n",
        "    lda_precision_test_k[i] = precision_score(y_test, predxclass)\n",
        "    lda_recall_test_k[i] = recall_score(y_test, predxclass)\n",
        "    lda_F1_score_test_k[i] = f1_score(y_test, predxclass)\n",
        "\n",
        "    qda = QuadraticDiscriminantAnalysis()\n",
        "    qda_fit = qda.fit(X_train, y_train)\n",
        "    predxclass = qda.predict(X_test)\n",
        "    qda_accurancy_test_k[i] = accuracy_score(y_test, predxclass) #same thing written before\n",
        "    qda_precision_test_k[i] = precision_score(y_test, predxclass)\n",
        "    qda_recall_test_k[i] = recall_score(y_test, predxclass)\n",
        "    qda_F1_score_test_k[i] = f1_score(y_test, predxclass)\n",
        "\n",
        "    LR = LogisticRegression()\n",
        "    lr_fit = LR.fit(X_train, y_train)\n",
        "    predxclass = LR.predict(X_test)\n",
        "    lr_accurancy_test_k[i] = accuracy_score(y_test, predxclass) #same thing written before\n",
        "    lr_precision_test_k[i] = precision_score(y_test, predxclass)\n",
        "    lr_recall_test_k[i] = recall_score(y_test, predxclass)\n",
        "    lr_F1_score_test_k[i] = f1_score(y_test, predxclass)\n",
        "\n",
        "    tree = DecisionTreeClassifier()\n",
        "    param_grid = {\n",
        "        'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
        "        'min_samples_leaf': [1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
        "    }\n",
        "    grid_search = GridSearchCV(estimator=tree, param_grid=param_grid, cv=10, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_params = grid_search.best_params_\n",
        "    max_depth_cv = grid_search.best_params_['max_depth']\n",
        "    min_samples_leaf_cv = grid_search.best_params_['min_samples_leaf']\n",
        "    tree = DecisionTreeClassifier(max_depth = max_depth_cv, min_samples_leaf=min_samples_leaf_cv)\n",
        "    treefit = tree.fit(X_train, y_train)\n",
        "    pY_test=treefit.predict_proba(X_test)\n",
        "    predxclass=np.argmax(pY_test,axis=1)\n",
        "    cdt_accurancy_test_k[i] = accuracy_score(y_test, predxclass) #same thing written before\n",
        "    cdt_precision_test_k[i] = precision_score(y_test, predxclass)\n",
        "    cdt_recall_test_k[i] = recall_score(y_test, predxclass)\n",
        "    cdt_F1_score_test_k[i] = f1_score(y_test, predxclass)\n",
        "\n",
        "    treebag = DecisionTreeClassifier()\n",
        "    param_grid = {\n",
        "        'n_estimators':[2, 5,10,25,50],\n",
        "        'max_samples':[0.8, 1.0],\n",
        "        'max_features':[0.8, 1.0]\n",
        "    }\n",
        "    bagging = BaggingClassifier(estimator=treebag)\n",
        "    grid_search = GridSearchCV(bagging, param_grid, cv=10)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_params = grid_search.best_params_\n",
        "    n_estimators_cv = grid_search.best_params_['n_estimators']\n",
        "    max_features_cv = grid_search.best_params_['max_features']\n",
        "    max_samples_cv = grid_search.best_params_['max_samples']\n",
        "    bagmod=BaggingClassifier(base_estimator=treebag, n_estimators=n_estimators_cv, max_features=max_features_cv, max_samples=max_samples_cv, random_state=0)\n",
        "    treemodfit=treebag.fit(X_train, y_train)\n",
        "    bagmodfit=bagmod.fit(X_train, y_train)\n",
        "    pY_test=bagmodfit.predict_proba(X_test)\n",
        "    predxclass=np.argmax(pY_test,axis=1)\n",
        "    bag_accurancy_test_k[i] = accuracy_score(y_test, predxclass) #same thing written before\n",
        "    bag_precision_test_k[i] = precision_score(y_test, predxclass)\n",
        "    bag_recall_test_k[i] = recall_score(y_test, predxclass)\n",
        "    bag_F1_score_test_k[i] = f1_score(y_test, predxclass)\n",
        "\n",
        "    param_grid = {\n",
        "        'n_estimators':[50, 100, 200],  \n",
        "        'max_depth':[3, 5, 7, 10], \n",
        "        'min_samples_split':[2, 5],\n",
        "        'min_samples_leaf':[1, 2]\n",
        "    }\n",
        "    RF = RandomForestClassifier()\n",
        "    grid_search = GridSearchCV(RF, param_grid, cv = 10)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_params = grid_search.best_params_\n",
        "    n_estimators_cv = grid_search.best_params_['n_estimators']\n",
        "    max_depth_cv = grid_search.best_params_['max_depth']\n",
        "    min_samples_split_cv = grid_search.best_params_['min_samples_split']\n",
        "    min_samples_leaf_cv = grid_search.best_params_['min_samples_leaf']\n",
        "    RF = RandomForestClassifier(max_depth=max_depth_cv, random_state=0, oob_score = True, max_features='sqrt', n_estimators=n_estimators_cv, min_samples_leaf=min_samples_leaf_cv, min_samples_split=min_samples_split_cv)\n",
        "    RFfit = RF.fit(X_train, y_train)\n",
        "    pY_test=RFfit.predict_proba(X_test)\n",
        "    predxclass=np.argmax(pY_test,axis=1)\n",
        "    rf_accurancy_test_k[i] = accuracy_score(y_test, predxclass) #same thing written before\n",
        "    rf_precision_test_k[i] = precision_score(y_test, predxclass)\n",
        "    rf_recall_test_k[i] = recall_score(y_test, predxclass)\n",
        "    rf_F1_score_test_k[i] = f1_score(y_test, predxclass)\n",
        "\n",
        "    param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 0.5]\n",
        "    }\n",
        "    ab = AdaBoostClassifier()\n",
        "    grid_search = GridSearchCV(ab, param_grid, cv = 10)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_params = grid_search.best_params_\n",
        "    n_estimators_cv = grid_search.best_params_['n_estimators']\n",
        "    learning_rate_cv = grid_search.best_params_['learning_rate']\n",
        "    ab = AdaBoostClassifier(n_estimators=n_estimators_cv, learning_rate=learning_rate_cv)\n",
        "    ab_fit = ab.fit(X_train, y_train)\n",
        "    pY_test = ab_fit.predict_proba(X_test)\n",
        "    predxclass = np.argmax(pY_test, axis=1)\n",
        "    ab_accurancy_test_k[i] = accuracy_score(y_test, predxclass)\n",
        "    ab_precision_test_k[i] = precision_score(y_test, predxclass)\n",
        "    ab_recall_test_k[i] = recall_score(y_test, predxclass)\n",
        "    ab_F1_score_test_k[i] = f1_score(y_test, predxclass)\n",
        "\n",
        "    gb = GradientBoostingClassifier()\n",
        "    param_grid = {\n",
        "        'loss': ['log_loss'],#, 'deviance', 'exponential'],\n",
        "        'learning_rate': [0.1],\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'max_depth': [3, 5],\n",
        "        'subsample': [0.8, 1.0],\n",
        "        'min_samples_split':[2, 3]\n",
        "    }\n",
        "    grid_search = GridSearchCV(gb, param_grid, cv = 5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_params = grid_search.best_params_\n",
        "    loss_cv = grid_search.best_params_['loss']\n",
        "    n_estimators_cv = grid_search.best_params_['n_estimators']\n",
        "    max_depth_cv = grid_search.best_params_['max_depth']\n",
        "    subsample_cv = grid_search.best_params_['subsample']\n",
        "    min_samples_split_cv = grid_search.best_params_['min_samples_split']\n",
        "    learning_rate_cv = grid_search.best_params_['learning_rate']\n",
        "    gb = GradientBoostingClassifier(loss=loss_cv, n_estimators=n_estimators_cv, max_depth=max_depth_cv,\n",
        "                                subsample=subsample_cv, min_samples_split=min_samples_split_cv, learning_rate=learning_rate_cv)\n",
        "    gb_fit = gb.fit(X_train, y_train)\n",
        "    pY_test = gb_fit.predict_proba(X_test)\n",
        "    predxclass = np.argmax(pY_test, axis=1)\n",
        "    gb_accurancy_test_k[i] = accuracy_score(y_test, predxclass)\n",
        "    gb_precision_test_k[i] = precision_score(y_test, predxclass)\n",
        "    gb_recall_test_k[i] = recall_score(y_test, predxclass)\n",
        "    gb_F1_score_test_k[i] = f1_score(y_test, predxclass)\n",
        "\n",
        "    stk_nb_fit = stk_nb.fit(X_train, y_train)\n",
        "    pY_test = stk_nb_fit.predict_proba(X_test)\n",
        "    predxclass = np.argmax(pY_test, axis = 1)\n",
        "    stk_accurancy_test_k[i] = accuracy_score(y_test, predxclass)\n",
        "    stk_precision_test_k[i] = precision_score(y_test, predxclass)\n",
        "    stk_recall_test_k[i] = recall_score(y_test, predxclass)\n",
        "    stk_F1_score_test_k[i] = f1_score(y_test, predxclass)\n",
        "    stk_lda_fit = stk_lda.fit(X_train, y_train)\n",
        "    pY_test = stk_lda_fit.predict_proba(X_test)\n",
        "    predxclass = np.argmax(pY_test, axis = 1)\n",
        "    stk_accurancy_test_k[i+5] = accuracy_score(y_test, predxclass)\n",
        "    stk_precision_test_k[i+5] = precision_score(y_test, predxclass)\n",
        "    stk_recall_test_k[i+5] = recall_score(y_test, predxclass)\n",
        "    stk_F1_score_test_k[i+5] = f1_score(y_test, predxclass)\n",
        "    stk_qda_fit = stk_qda.fit(X_train, y_train)\n",
        "    pY_test = stk_qda_fit.predict_proba(X_test)\n",
        "    predxclass = np.argmax(pY_test, axis = 1)\n",
        "    stk_accurancy_test_k[i+10] = accuracy_score(y_test, predxclass)\n",
        "    stk_precision_test_k[i+10] = precision_score(y_test, predxclass)\n",
        "    stk_recall_test_k[i+10] = recall_score(y_test, predxclass)\n",
        "    stk_F1_score_test_k[i+10] = f1_score(y_test, predxclass)\n",
        "    stk_lr_fit = stk_lr.fit(X_train, y_train)\n",
        "    pY_test = stk_lr_fit.predict_proba(X_test)\n",
        "    predxclass = np.argmax(pY_test, axis = 1)\n",
        "    stk_accurancy_test_k[i+15] = accuracy_score(y_test, predxclass)\n",
        "    stk_precision_test_k[i+15] = precision_score(y_test, predxclass)\n",
        "    stk_recall_test_k[i+15] = recall_score(y_test, predxclass)\n",
        "    stk_F1_score_test_k[i+15] = f1_score(y_test, predxclass)\n",
        "    stk_dt_fit = stk_dt.fit(X_train, y_train)\n",
        "    pY_test = stk_dt_fit.predict_proba(X_test)\n",
        "    predxclass = np.argmax(pY_test, axis = 1)\n",
        "    stk_accurancy_test_k[i+20] = accuracy_score(y_test, predxclass)\n",
        "    stk_precision_test_k[i+20] = precision_score(y_test, predxclass)\n",
        "    stk_recall_test_k[i+20] = recall_score(y_test, predxclass)\n",
        "    stk_F1_score_test_k[i+20] = f1_score(y_test, predxclass)\n",
        "\n",
        "nb_acc_final = np.mean(nb_accurancy_test_k)\n",
        "print(f\"Accuracy using nb is: {nb_acc_final:.3f}\")\n",
        "nb_prec_final = np.mean(nb_precision_test_k)\n",
        "print(f\"Precision using nb is: {nb_prec_final:.3f}\")\n",
        "nb_rec_final = np.mean(nb_recall_test_k)\n",
        "print(f\"Recall using nb is: {nb_rec_final:.3f}\")\n",
        "nb_F1_final = np.mean(nb_F1_score_test_k)\n",
        "print(f\"F1-score using nb is: {nb_F1_final:.3f}\")\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "lda_acc_final = np.mean(lda_accurancy_test_k)\n",
        "print(f\"Accuracy using lda is: {lda_acc_final:.3f}\")\n",
        "lda_prec_final = np.mean(lda_precision_test_k)\n",
        "print(f\"Precision using lda is: {lda_prec_final:.3f}\")\n",
        "lda_rec_final = np.mean(lda_recall_test_k)\n",
        "print(f\"Recall using lda is: {lda_rec_final:.3f}\")\n",
        "lda_F1_final = np.mean(lda_F1_score_test_k)\n",
        "print(f\"F1-score using lda is: {lda_F1_final:.3f}\")\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "qda_acc_final = np.mean(qda_accurancy_test_k)\n",
        "print(f\"Accuracy using qda is: {qda_acc_final:.3f}\")\n",
        "qda_prec_final = np.mean(qda_precision_test_k)\n",
        "print(f\"Precision using qda is: {qda_prec_final:.3f}\")\n",
        "qda_rec_final = np.mean(qda_recall_test_k)\n",
        "print(f\"Recall using qda is: {qda_rec_final:.3f}\")\n",
        "qda_F1_final = np.mean(qda_F1_score_test_k)\n",
        "print(f\"F1-score using qda is: {qda_F1_final:.3f}\")\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "lr_acc_final = np.mean(lr_accurancy_test_k)\n",
        "print(f\"Accuracy using lr is: {lr_acc_final:.3f}\")\n",
        "lr_prec_final = np.mean(lr_precision_test_k)\n",
        "print(f\"Precision using lr is: {lr_prec_final:.3f}\")\n",
        "lr_rec_final = np.mean(lr_recall_test_k)\n",
        "print(f\"Recall using lr is: {lr_rec_final:.3f}\")\n",
        "lr_F1_final = np.mean(lr_F1_score_test_k)\n",
        "print(f\"F1-score using lr is: {lr_F1_final:.3f}\")\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "cdt_acc_final = np.mean(cdt_accurancy_test_k)\n",
        "print(f\"Accuracy using cdt is: {cdt_acc_final:.3f}\")\n",
        "cdt_prec_final = np.mean(cdt_precision_test_k)\n",
        "print(f\"Precision using cdt is: {cdt_prec_final:.3f}\")\n",
        "cdt_rec_final = np.mean(cdt_recall_test_k)\n",
        "print(f\"Recall using cdt is: {cdt_rec_final:.3f}\")\n",
        "cdt_F1_final = np.mean(cdt_F1_score_test_k)\n",
        "print(f\"F1-score using cdt is: {cdt_F1_final:.3f}\")\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "bag_acc_final = np.mean(bag_accurancy_test_k)\n",
        "print(f\"Accuracy using bag is: {bag_acc_final:.3f}\")\n",
        "bag_prec_final = np.mean(bag_precision_test_k)\n",
        "print(f\"Precision using bag is: {bag_prec_final:.3f}\")\n",
        "bag_rec_final = np.mean(bag_recall_test_k)\n",
        "print(f\"Recall using bag is: {bag_rec_final:.3f}\")\n",
        "bag_F1_final = np.mean(bag_F1_score_test_k)\n",
        "print(f\"F1-score using bag is: {bag_F1_final:.3f}\")\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "rf_acc_final = np.mean(rf_accurancy_test_k)\n",
        "print(f\"Accuracy using rf is: {rf_acc_final:.3f}\")\n",
        "rf_prec_final = np.mean(rf_precision_test_k)\n",
        "print(f\"Precision using rf is: {rf_prec_final:.3f}\")\n",
        "rf_rec_final = np.mean(rf_recall_test_k)\n",
        "print(f\"Recall using rf is: {rf_rec_final:.3f}\")\n",
        "rf_F1_final = np.mean(rf_F1_score_test_k)\n",
        "print(f\"F1-score using rf is: {rf_F1_final:.3f}\")\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "ab_acc_final = np.mean(ab_accurancy_test_k)\n",
        "print(f\"Accuracy using ab is: {ab_acc_final:.3f}\")\n",
        "ab_prec_final = np.mean(ab_precision_test_k)\n",
        "print(f\"Precision using ab is: {ab_prec_final:.3f}\")\n",
        "ab_rec_final = np.mean(ab_recall_test_k)\n",
        "print(f\"Recall using ab is: {ab_rec_final:.3f}\")\n",
        "ab_F1_final = np.mean(ab_F1_score_test_k)\n",
        "print(f\"F1-score using ab is: {ab_F1_final:.3f}\")\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "gb_acc_final = np.mean(gb_accurancy_test_k)\n",
        "print(f\"Accuracy using gb is: {gb_acc_final:.3f}\")\n",
        "gb_prec_final = np.mean(gb_precision_test_k)\n",
        "print(f\"Precision using gb is: {gb_prec_final:.3f}\")\n",
        "gb_rec_final = np.mean(gb_recall_test_k)\n",
        "print(f\"Recall using gb is: {gb_rec_final:.3f}\")\n",
        "gb_F1_final = np.mean(gb_F1_score_test_k)\n",
        "print(f\"F1-score using gb is: {gb_F1_final:.3f}\")\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "stk_acc_final = np.mean(stk_accurancy_test_k)\n",
        "print(f\"Accuracy using stk is: {stk_acc_final:.3f}\")\n",
        "stk_prec_final = np.mean(stk_precision_test_k)\n",
        "print(f\"Precision using stk is: {stk_prec_final:.3f}\")\n",
        "stk_rec_final = np.mean(stk_recall_test_k)\n",
        "print(f\"Recall using stk is: {stk_rec_final:.3f}\")\n",
        "stk_F1_final = np.mean(stk_F1_score_test_k)\n",
        "print(f\"F1-score using stk is: {stk_F1_final:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "Before showing our results, we wish to clarify what are the criteria that we are going to use to decide which model is better. Since this is a clinical dataset, talking about a healthcare problem, we think that is more appropriate to penalize the presence of false negatives, because the biggest threat is classifying as healthy a patient that in reality is at risk. \n",
        "\n",
        "Thus, we take into account all the indexes but we are going to focus particularly on recall, that is given by the formula $\\frac{TP}{TP+FN}$ which means that the more false negative discoveries we find, the lower the values of recall is. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Boxplot of \"accuracy\" over the different models:\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Boxplot of \"precision\" over the different models:\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Boxplot of \"recall\" over the different models:\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Boxplot of \"F1-score\" over the different models:\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABDUElEQVR4nO3deVyVZf7/8TccZRN3FFwwLDQwd8w1SicczGU0M20hiZRpc/IblUU5WlNJm0szmTYl6mRTTkZONY4tFEUTZXPQygnUSsRJQU0FBQXl3L8//HGmE4dVDudw83o+Hufhg3v9XHKWN9e5r+v2MgzDEAAAgEl4u7sAAACAxkS4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAAptLK3QU0NZvNpgMHDqht27by8vJydzkAAKAODMPQiRMn1L17d3l719w30+LCzYEDBxQaGuruMgAAQAPs379fPXv2rHGbFhdu2rZtK+ncf067du3cXA0AAKiL4uJihYaG2j/Ha9Liwk3lV1Ht2rUj3AAA0MzU5ZISLigGAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACmQrgBAACm4vZws3LlSoWFhcnPz08jRozQtm3bqt32zJkz+sMf/qCLLrpIfn5+GjRokLZu3dqE1QIAgJ+rqKhQRkaGXn31VWVkZKiiosLdJbk33GzcuFFJSUlavHixsrOzNWjQIMXGxurQoUNOt1+4cKFeeOEF/elPf9K3336r2267TVdffbW2b9/exJUDAIC0tDSFh4dr3LhxuuGGGzRu3DiFh4crLS3NrXW5NdwsW7ZMiYmJSkhIUL9+/bR69WoFBAQoNTXV6fYvv/yyHnzwQU2cOFEXXnihbr/9dk2cOFFLly6t9hxlZWUqLi52eAAAgPOTlpamGTNmaMCAAcrKytKJEyeUlZWlAQMGaMaMGW4NOG4LN+Xl5bJarYqJiflfMd7eiomJUVZWltN9ysrK5Ofn57DM399fn376abXnSUlJUfv27e2P0NDQxmkAAAAtVEVFhe655x5NnjxZmzdv1siRIxUYGKiRI0dq8+bNmjx5su699163fUXltnBz5MgRVVRUKDg42GF5cHCwCgoKnO4TGxurZcuWac+ePbLZbHr//feVlpamgwcPVnue5ORkFRUV2R/79+9v1HYAANDSZGZmKi8vTw8++KC8vR2jhLe3t5KTk7V3715lZma6pT63X1BcH88++6z69OmjiIgI+fj4aN68eUpISKjyH/tzvr6+ateuncMDAAA0XGWnQv/+/Z2ur1xeU+eDK7kt3AQFBclisaiwsNBheWFhoUJCQpzu06VLF23evFklJSXat2+fcnNzFRgYqAsvvLApSgYAAJK6desmSdq5c6fT9ZXLK7dram4LNz4+PoqKilJ6erp9mc1mU3p6ukaNGlXjvn5+furRo4fOnj2rN954Q1OnTnV1uQAA4P+Ljo5WWFiYlixZIpvN5rDOZrMpJSVFvXv3VnR0tFvqc+vXUklJSXrxxRe1fv165eTk6Pbbb1dJSYkSEhIkSbNnz1ZycrJ9+y+++EJpaWn64YcflJmZqQkTJshms2nBggXuagIAAC2OxWLR0qVL9c4772jatGkOo6WmTZumd955R88884wsFotb6mvllrP+f7NmzdLhw4e1aNEiFRQUaPDgwdq6dav9IuP8/HyH62lOnz6thQsX6ocfflBgYKAmTpyol19+WR06dHBTCwAAaJmmT5+uTZs26Z577tHo0aPty3v37q1NmzZp+vTpbqvNyzAMw21nd4Pi4mK1b99eRUVFXFwMAMB5qqioUGZmpg4ePKhu3bopOjraJT029fn8dmvPDQAAaN4sFovGjh3r7jIcNKuh4AAAALUh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFNhEj8AAFAnpaWlys3NrbL81KlTysvLU1hYmPz9/Z3uGxERoYCAAFeXKIlwAwAA6ig3N1dRUVEN2tdqtWro0KGNXJFzhBsAAFAnERERslqtVZbn5OQoLi5OGzZsUGRkZLX7NhXCDQAAqJOAgIAae18iIyObrHemJlxQDAAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATMXt4WblypUKCwuTn5+fRowYoW3bttW4/YoVK3TxxRfL399foaGhuvvuu3X69OkmqhYAAHg6t4abjRs3KikpSYsXL1Z2drYGDRqk2NhYHTp0yOn2f/3rX/XAAw9o8eLFysnJ0Zo1a7Rx40Y9+OCDTVw5AADwVG4NN8uWLVNiYqISEhLUr18/rV69WgEBAUpNTXW6/WeffaYxY8bohhtuUFhYmH7961/r+uuvr7W3BwAAtBxuCzfl5eWyWq2KiYn5XzHe3oqJiVFWVpbTfUaPHi2r1WoPMz/88IO2bNmiiRMnVnuesrIyFRcXOzwAAIB5tXLXiY8cOaKKigoFBwc7LA8ODlZubq7TfW644QYdOXJEl112mQzD0NmzZ3XbbbfV+LVUSkqKHnnkkUatHQAAeC63X1BcHxkZGVqyZImef/55ZWdnKy0tTf/4xz/06KOPVrtPcnKyioqK7I/9+/c3YcUAAKCpua3nJigoSBaLRYWFhQ7LCwsLFRIS4nSf3//+97rppps0d+5cSdKAAQNUUlKi3/72t3rooYfk7V01q/n6+srX17fxGwAAADyS23pufHx8FBUVpfT0dPsym82m9PR0jRo1yuk+paWlVQKMxWKRJBmG4bpiAQBAs+G2nhtJSkpKUnx8vIYNG6bhw4drxYoVKikpUUJCgiRp9uzZ6tGjh1JSUiRJU6ZM0bJlyzRkyBCNGDFC3333nX7/+99rypQp9pADAABaNreGm1mzZunw4cNatGiRCgoKNHjwYG3dutV+kXF+fr5DT83ChQvl5eWlhQsX6scff1SXLl00ZcoUPf744+5qAgAA8DBeRgv7Pqe4uFjt27dXUVGR2rVr5+5yAABo9rKzsxUVFSWr1aqhQ4e65Bz1+fxuVqOlAAAAakO4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApuIR4WblypUKCwuTn5+fRowYoW3btlW77dixY+Xl5VXlMWnSpCasGAAAeCq3h5uNGzcqKSlJixcvVnZ2tgYNGqTY2FgdOnTI6fZpaWk6ePCg/bFz505ZLBZde+21TVw5AADwRG4PN8uWLVNiYqISEhLUr18/rV69WgEBAUpNTXW6fadOnRQSEmJ/vP/++woICKg23JSVlam4uNjhAQAAzMut4aa8vFxWq1UxMTH2Zd7e3oqJiVFWVladjrFmzRpdd911atOmjdP1KSkpat++vf0RGhraKLUDAADP5NZwc+TIEVVUVCg4ONhheXBwsAoKCmrdf9u2bdq5c6fmzp1b7TbJyckqKiqyP/bv33/edQMAAM/Vyt0FnI81a9ZowIABGj58eLXb+Pr6ytfXtwmrAgAA7uTWnpugoCBZLBYVFhY6LC8sLFRISEiN+5aUlOi1117TnDlzXFkiAABoZtzac+Pj46OoqCilp6dr2rRpkiSbzab09HTNmzevxn1ff/11lZWVKS4urgkqda60tFS5ublVlp86dUp5eXkKCwuTv79/lfUREREKCAhoihIBAGhx3P61VFJSkuLj4zVs2DANHz5cK1asUElJiRISEiRJs2fPVo8ePZSSkuKw35o1azRt2jR17tzZHWVLknJzcxUVFVXv/axWq4YOHeqCigAAgNvDzaxZs3T48GEtWrRIBQUFGjx4sLZu3Wq/yDg/P1/e3o7fnu3atUuffvqp3nvvPXeUbBcRESGr1VpleU5OjuLi4rRhwwZFRkY63Q8AALiG28ONJM2bN6/ar6EyMjKqLLv44otlGIaLq6pdQEBAjT0wkZGR9NAAANDE3D6JHwAAQGMi3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFPxiEn8AFSvoqJCmZmZOnjwoLp166bo6GhZLBZ3lwUAHoueG8CDpaWlKTw8XOPGjdMNN9ygcePGKTw8XGlpae4uDQA8FuEG8FBpaWmaMWOGBgwYoKysLJ04cUJZWVkaMGCAZsyYQcABgGoQbgAPVFFRoXvuuUeTJ0/W5s2bNXLkSAUGBmrkyJHavHmzJk+erHvvvVcVFRXuLhUAPA7hBvBAmZmZysvL04MPPihvb8eXqbe3t5KTk7V3715lZma6qUIA8FyEG8ADHTx4UJLUv39/p+srl1duBwD4H8IN4IG6desmSdq5c6fT9ZXLK7cDAPwP4QbwQNHR0QoLC9OSJUtks9kc1tlsNqWkpKh3796Kjo52U4UA4LkIN4AHslgsWrp0qd555x1NmzbNYbTUtGnT9M477+iZZ55hvhsAcIJJ/AAPNX36dG3atEn33HOPRo8ebV/eu3dvbdq0SdOnT3djdQDguQg3gAebPn26pk6dygzFAFAPhBvAw1ksFo0dO9bdZQBAs8E1NwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQYCl5He/bs0YkTJ+q0bU5OjsO/ddG2bVv16dOnQbUBAID/IdzUwZ49e9S3b9967xcXF1ev7Xfv3k3AAQDgPBFu6qCyx2bDhg2KjIysdftTp04pLy9PYWFh8vf3r3X7nJwcxcXF1blnCAAAVI9wUw+RkZEaOnRonbYdM2aMi6sBAADOcEExAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFbeHm5UrVyosLEx+fn4aMWKEtm3bVuP2x48f15133qlu3brJ19dXffv21ZYtW5qoWgAA4OncOhR848aNSkpK0urVqzVixAitWLFCsbGx2rVrl7p27Vpl+/Lyco0fP15du3bVpk2b1KNHD+3bt08dOnRo+uIBAIBHcmu4WbZsmRITE5WQkCBJWr16tf7xj38oNTVVDzzwQJXtU1NTdfToUX322Wdq3bq1JCksLKwpSwYAAB7ObeGmvLxcVqtVycnJ9mXe3t6KiYlRVlaW033eeustjRo1Snfeeaf+/ve/q0uXLrrhhht0//33y2KxON2nrKxMZWVl9p+Li4sbtyEAAJiQq++pKLnuvopuCzdHjhxRRUWFgoODHZYHBwcrNzfX6T4//PCDPvzwQ914443asmWLvvvuO91xxx06c+aMFi9e7HSflJQUPfLII41ePwAAZtVU91SUXHNfxWZ1+wWbzaauXbvqz3/+sywWi6KiovTjjz/q6aefrjbcJCcnKykpyf5zcXGxQkNDm6pkj1daWlptmKztHlkREREKCAhwdYkAgCbm6nsqSq69r6Lbwk1QUJAsFosKCwsdlhcWFiokJMTpPt26dVPr1q0dvoKKjIxUQUGBysvL5ePjU2UfX19f+fr6Nm7xJpKbm6uoqKgG7Wu1Wut8ry0AQPPTXO+p6LZw4+Pjo6ioKKWnp2vatGmSzvXMpKena968eU73GTNmjP7617/KZrPJ2/vcKPbdu3erW7duToMNahcRESGr1ep0XWWqri65R0REuLo8AADq7bzCzXfffafvv/9el19+ufz9/WUYhry8vOq8f1JSkuLj4zVs2DANHz5cK1asUElJiX301OzZs9WjRw+lpKRIkm6//XY999xzmj9/vn73u99pz549WrJkie66667zaUaLFhAQUGsqr09yBwDA3RoUbn766SfNmjVLH374oby8vLRnzx5deOGFmjNnjjp27KilS5fW6TizZs3S4cOHtWjRIhUUFGjw4MHaunWr/SLj/Px8ew+NJIWGhurdd9/V3XffrYEDB6pHjx6aP3++7r///oY0o8Wpz5XvUsOufnfVle8AANRVg8LN3XffrVatWik/P9/h64pZs2YpKSmpzuFGkubNm1ft11AZGRlVlo0aNUqff/55vWtu6Rp65btU/6vfXXHlOwAAddWgcPPee+/p3XffVc+ePR2W9+nTR/v27WuUwtC46nvlu1T/q99deeU7AAB11aBwU1JS4nQI8NGjRxmZ5OHqe/2MJ139DgBAXTToxpnR0dH6y1/+Yv/Zy8tLNptNTz31lMaNG9doxQEAANRXg3punnrqKV155ZX697//rfLyci1YsED/+c9/dPToUf3rX/9q7BoBAADqrEE9N/3799fu3bt12WWXaerUqSopKdH06dO1fft2XXTRRY1dIwAAQJ3Vu+fmzJkzmjBhglavXq2HHnrIFTUBjaKiokKZmZk6ePCgunXrpujo6GpvsAoAMI9699y0bt1aX3/9tStqARpNWlqawsPDNW7cON1www0aN26cwsPDlZaW5u7SAAAu1qBrbuLi4rRmzRo98cQTjV2PR/I6e1pDQrzlf3y3dKBB3+TVyP/4bg0J8ZbX2dONfuyWKC0tTTNmzNDkyZP16quvqn///tq5c6eWLFmiGTNmaNOmTZo+fbq7ywQAuEiDws3Zs2eVmpqqDz74QFFRUWrTpo3D+mXLljVKcZ7C72S+sm8NlD65Vfqk8Y8fKSn71kDlnMyXNLrxT9CCVFRU6J577tHkyZO1efNm+wzXI0eO1ObNmzVt2jTde++9mjp1Kl9RAYBJNSjc7Ny50z5Xyu7dux3W1efeUs3F6cBeGvrCSb3yyiuKdMHNInNyc3XjjTdqzcRejX7sliYzM1N5eXl69dVXHW7dIUne3t5KTk7W6NGjlZmZqbFjx7qnSACASzUo3Hz00UeNXYdHM1r5aXuBTac69JW6D270458qsGl7gU1GK79GP3ZLc/DgQUnnRvQ5U7m8cjsAgPmc113BJem///2vJFW5FQPgDt26dZN0rndx5MiRVdbv3LnTYTsAnq+0tFS5ublVltd2i5iIiAins+nD/BoUbmw2mx577DEtXbpUJ0+elHTubtD33HOPHnrooSpfBwBNJTo6WmFhYVqyZInDNTfSuedtSkqKevfurejoaDdWCaA+cnNzFRUVVe/9rFZrvW43A/NoULh56KGH7KOlKu899Omnn+rhhx/W6dOn9fjjjzdqkUBdWSwWLV26VDNmzNC0adOUnJxsHy2VkpKid955R5s2beJiYqAZiYiIkNVqrbK88ma91d0QOMIF10iieWhQuFm/fr1eeukl/eY3v7EvGzhwoHr06KE77riDcAO3mj59ujZt2qR77rlHo0f/b/RZ7969GQYONEMBAQE19sDU94bAML8GhZujR486TcQRERE6evToeRcFnK/p06dr6tSpzFAMAC1Qg8LNoEGD9Nxzz+mPf/yjw/LnnntOgwYNapTCgPNlsVgY7g0ALVCD7wo+adIkffDBBxo1apQkKSsrS/v379eWLVsatUAAAID6aNCwpiuuuEK7du3S1VdfrePHj+v48eOaPn26du3axSgUAADgVg2e56ZHjx5cOAwAADxOg3pu1q5dq9dff73K8tdff13r168/76IAAAAaqkHhJiUlRUFBQVWWd+3aVUuWLDnvogAAABqqQeEmPz9fvXv3rrL8ggsuUH5+/nkXBQAA0FANuuama9eu+vrrrxUWFuaw/KuvvlLnzp0boy7A1Pbs2aMTJ05UWV55r5z6cnZvnbZt26pPnz4NLRFwi+peG87k5OQ4/FtXvDbMr0Hh5vrrr9ddd92ltm3b6vLLL5ckffzxx5o/f76uu+66Ri3QE5SWlkqSsrOz67R9bTdz+6X6vjDRvO3Zs0d9+/ZtknPt3r27yd/EG3qTQ4kbHbZ0DX1txMXF1Xsfd7w20HQaFG4effRR5eXl6corr1SrVucOYbPZNHv2bFNec1P5Rp2YmOjS87Rt29alx4dnqPyr1Nn9cBqr56bynjt1/Qu4MTX0JocSNzps6Wp6bThT3z8kJfe+NtB0GhRufHx8tHHjRj322GPasWOH/P39NWDAAF1wwQWNXZ9HmDZtmqS6/1VZ283cnKGbtOWp7n44lTejba4aepPDyn2B+twrqrm/XuAaDZ7nRpL69OmjPn36qKKiQt98843atWunjh07NlZtHiMoKEhz586t937czA0tETc5BOBuDRot9X//939as2aNJKmiokJXXHGFhg4dqtDQUGVkZDRmfQAAAPXSoHCzadMm+w0y3377bf3www/Kzc3V3XffrYceeqhRCwQAAKiPBn0tdeTIEYWEhEiStmzZopkzZ6pv37665ZZb9OyzzzZqgQA8F8N2AXiiBoWb4OBgffvtt+rWrZu2bt2qVatWSTo3BNRisTRqgQA8E8N2AXiqBoWbhIQEzZw5U926dZOXl5diYmIkSV988QWjHYAWgmG7ADxVg8LNww8/rP79+2v//v269tpr5evrK0myWCx64IEHGrVAAJ6NYbsAPE2Dh4LPmDFDkvTf//5XNptN3t7eio+Pb7TCAAAAGqJBo6V+rl+/fg2aUfXnVq5cqbCwMPn5+WnEiBHatm1btduuW7dOXl5eDg8/P7/zOj8AADCP8w43hmGc1/4bN25UUlKSFi9erOzsbA0aNEixsbE6dOhQtfu0a9dOBw8etD/27dt3XjUAAADzOO9wc76WLVumxMREJSQkqF+/flq9erUCAgKUmppa7T5eXl4KCQmxP4KDg5uwYgAA4MnO6/YLkvTggw+qU6dODdq3vLxcVqtVycnJ9mXe3t6KiYlRVlZWtfudPHlSF1xwgWw2m4YOHaolS5bokksucbptWVmZysrK7D8XFxc3qFYA5uVsvp7GuompxFw9deV19rSGhHjL//hu6YBr/vb2P75bQ0K85XX2tEuOr/JS5W9PV0lJSZVVZWVlOnDgQL0P2b17d/vAnUpt2rRRryFXSj613++wJTrvcPPzYFJfR44cUUVFRZWel+DgYPuduH/p4osvVmpqqgYOHKiioiI988wzGj16tP7zn/+oZ8+eVbZPSUnRI4880uAaAZhbQ+frqS/m6qmd38l8Zd8aKH1yq/SJa84RKSn71kDlnMyXNLrRj5+/PV29/ln9XE6DG3LQ/dWcSxvUa8SUhhzR9M473Pzc/v37tXjx4hq/Ujpfo0aN0qhRo+w/jx49WpGRkXrhhRf06KOPVtk+OTlZSUlJ9p+Li4sVGhrqsvoANC/VzdfTWD03zNVTd6cDe2noCyf1yiuvKNJFc6bl5Obqxhtv1JqJvVxy/J+8OmvaCyf12GOPqXfv3g7rGqvnZu/evVq4cKHWTOws17Si+WvUcHP06FGtX7++zuEmKChIFotFhYWFDssLCwvtt3eoTevWrTVkyBB99913Ttf7+vpW6c4DgF9yNl8P8/I0LaOVn7YX2HSqQ1+p+2CXnONUgU3bC2wyWrlmlG1lG0KGxCrSyfxPgxvhHKeys7W94EGXtcEM6hVu3nrrrRrX//DDD/U6uY+Pj6KiopSenq5p06ZJkmw2m9LT0zVv3rw6HaOiokLffPONJk6cWK9zAwAAc6pXuJk2bZq8vLxqHP7t5eVVrwKSkpIUHx+vYcOGafjw4VqxYoVKSkqUkJAgSZo9e7Z69OihlJQUSdIf/vAHjRw5UuHh4Tp+/Liefvpp7du3T3Pnzq3XeQEAgDnVK9x069ZNzz//vKZOnep0/Y4dOxQVFVWvAmbNmqXDhw9r0aJFKigo0ODBg7V161b7Rcb5+fny9v7fVfPHjh1TYmKiCgoK1LFjR0VFRemzzz5Tv3796nVeAABgTvUKN1FRUbJardWGm9p6daozb968ar+GysjIcPh5+fLlWr58eb3PAQAAWoZ6hZv77rvP6dj9SuHh4froo4/Ou6jmorS01OmQ9ZycHId/fykiIkIBAcxN0FCunpNEcu28JKaYywOAqTX396l6hZsePXpUGdr2c23atNEVV1xx3kU1F7m5uTV+DRcX53yuA6vVWue7KMNRU81JIrluXhIzzOUBwNya+/tUvcJNnz59dPDgQXXt2lXSuetl/vjHP7bY2x9ERETIarVWWV7Zi1Bdr0CEi+ZvaAlcPSeJ5Pp5ScwwlwcAc2vu71P1Cje/vJ5my5Yt9lFMLVFAQEC1PTDMj+FazXlOEjPM5QHA3Jr7+5Tbb5wJAADQmOoVbry8vKrMY1PfeW0AAABcqd5fS91888322xmcPn1at912m9q0aeOwXVpaWuNVCJhMaWmpJCk7O7vO+9R2HdcvVTdSDwBagnqFm/j4eIefqxsNBM/T3If1mUnl9AGJiYkuP1fbtm1ddmyeUwA8Vb3Czdq1a11VB1ysuQ/rM5PK+6g5m++ocqRWff1y9Jjk2rl6JJ5TADxXo94VHJ6ruQ/rM5OgoKBq74V2PtMLNPXEkDynAHgqwk0L0dyH9bUUzWl6AZ5TADwVQ8EBAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpMFqqhTDLrLhMHAcAqA3hpoUwy6y4TBwHAKgN4aaFqGlW3OpUzpbrbPbb6rh6VlwmjgMA1IZw00LUNCtubSIjI6udWK6pMXEcAKA2XFAMAABMhXADAABMhXADAABMhWtu0KzUd0h7fYezS00zpB0A4DqEGzQrZhnSDgBwHcINmpX6DmlvyHB2yfVD2gEArkO4QbPS0CHtnjScHQDgWlxQDAAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIXRUgAAj8AknZ6juf8uCDctXGlpqX1ivF+qfOJV9wSs61wzTaG6djSnNgAtHZN0eo7m/rsg3LRwubm5ioqKqnGbuLg4p8utVqvHzB1TWzuaQxuAlo5JOj1Hc/9dEG5auIiICFmtVqfrautmjIiIcHV5dVZdO5pTG4CWjkk6PUdz/114RLhZuXKlnn76aRUUFGjQoEH605/+pOHDh9e632uvvabrr79eU6dO1ebNm11fqAkFBATU+EQcM2ZME1bTcDW1o7m0AQDQONw+Wmrjxo1KSkrS4sWLlZ2drUGDBik2NlaHDh2qcb+8vDzde++9io6ObqJKAQBAc+D2nptly5YpMTFRCQkJkqTVq1frH//4h1JTU/XAAw843aeiokI33nijHnnkEWVmZur48ePVHr+srExlZWX2n4uLixu1fgDNm9fZ0xoS4i3/47ulA43/957/8d0aEuItr7OnG/3YAJxza7gpLy+X1WpVcnKyfZm3t7diYmKUlZVV7X5/+MMf1LVrV82ZM0eZmZk1niMlJUWPPPJIo9UMwFz8TuYr+9ZA6ZNbpU8a//iRkrJvDVTOyXxJoxv/BACqcGu4OXLkiCoqKhQcHOywPDg4uNrhyZ9++qnWrFmjHTt21OkcycnJSkpKsv9cXFys0NDQBtcMwFxOB/bS0BdO6pVXXlGkCy4wz8nN1Y033qg1E3s1+rEBOOf2r6Xq48SJE7rpppv04osvKigoqE77+Pr6ytfX18WVAWiujFZ+2l5g06kOfaXugxv9+KcKbNpeYJPRyq/Rjw3AObeGm6CgIFksFhUWFjosLywsVEhISJXtv//+e+Xl5WnKlCn2ZTabTZLUqlUr7dq1SxdddJFriwYAAB7NraOlfHx8FBUVpfT0dPsym82m9PR0jRo1qsr2ERER+uabb7Rjxw774ze/+Y3GjRunHTt28HUTAABw/9dSSUlJio+P17BhwzR8+HCtWLFCJSUl9tFTs2fPVo8ePZSSkiI/Pz/179/fYf8OHTpIUpXlAACgZXJ7uJk1a5YOHz6sRYsWqaCgQIMHD9bWrVvtFxnn5+fL29vt0/EAAIBmwu3hRpLmzZunefPmOV2XkZFR477r1q1r/IIAAECz5RHhBgDQ+EpLS6udVqMu912ryw0TAU9EuAEAk8rNzVVUVFSD9rVarR5xA0Sp+pCWk5Pj8O8vuSOglZaWSpKys7PrvE9tQfOXqmsv/odwAwAmFRERIavV6nRdTk6O4uLitGHDBkVGRjrd11PUFtLi4uKcLndHQKsMYYmJiS4/V9u2bV1+juaKcAMAJrBnzx6dOHGi0Y7nrKekbdu26tOnT6Odo66qC2l1+WqtqU2bNs1+7rr2GtUWNJ1x1++iuSDcAEAzt2fPHvXt27dB+1bX61Gd3bt3N/mHakBAQLU9MGPGjGnSWmoTFBSkuXPnNmjfyMhIj/kqsLkj3ABAM1fZY1Ofv/wbcp1HXFxco/YOAa5CuAEAk6jvX/6e1usBNBZmxwMAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKbC7RcANEhpaakkKTs7u07b1/deRtK5+xm5mqvb0RRtOH3iqIaEeGvf52/J//juOu1TVlamAwcOqHv37vL19a11+4K9ezUkxFteZ0+fb7ktVmlpqdO7rVc+R6p7rtTnDuM4h3ADoEEq36QTExNdfq62bdu67NhN1Q5XtqHwP58q+9ZA6dBy6VDd9xssSfvrtm2kpIm3Birf+Kn+BULSuedaVFRUteuru0O71WrlbuH1RLgB0CDTpk2TVPe/KivvKl2fO1dL50JBnz59GlpmrZqiHa5uQ/TVc/Tmm1JYWJj8/PzqtM/evXu1cOFCPfbYY+rdu3ed9mnTpo16DbnyfEpt0SIiImS1Wqssr603MCIioinKMxXCDYAGCQoK0ty5c+u9X33vXO1qZmhHULdQXX3Hw/Xa51R2trYXPKiQIbGK9JB2mF1AQEC1zxnu0N64uKAYAACYCj03AGBS1V3AKnERK8yNcAMAJlXbBawSF7HCnAg3AGBS1V3AKnERK8yNcAMAJlXTBawSF7HCvLigGAAAmAo9NwAAoE4aOsuy1LQXqRNuAABAnTR0lmWpaS9SJ9wAAIA6aegsy5X7NhXCDQAAqJPmMssyFxQDAABTIdwAAABTIdwAAABTIdwAAABT8Yhws3LlSoWFhcnPz08jRozQtm3bqt02LS1Nw4YNU4cOHdSmTRsNHjxYL7/8chNWCwAAPJnbw83GjRuVlJSkxYsXKzs7W4MGDVJsbKwOHTrkdPtOnTrpoYceUlZWlr7++mslJCQoISFB7777bhNXDgAAPJHbw82yZcuUmJiohIQE9evXT6tXr1ZAQIBSU1Odbj927FhdffXVioyM1EUXXaT58+dr4MCB+vTTT5u4cgAA4IncGm7Ky8tltVoVExNjX+bt7a2YmBhlZWXVur9hGEpPT9euXbt0+eWXO92mrKxMxcXFDg8AAGBebg03R44cUUVFhYKDgx2WBwcHq6CgoNr9ioqKFBgYKB8fH02aNEl/+tOfNH78eKfbpqSkqH379vZHaGhoo7YBAAB4Frd/LdUQbdu21Y4dO/Tll1/q8ccfV1JSkjIyMpxum5ycrKKiIvtj//79TVssAABoUm69/UJQUJAsFosKCwsdlhcWFiokJKTa/by9vRUeHi5JGjx4sHJycpSSkqKxY8dW2dbX11e+vr6NWjcAAPBcbu258fHxUVRUlNLT0+3LbDab0tPTNWrUqDofx2azqayszBUlAgCAZsbtN85MSkpSfHy8hg0bpuHDh2vFihUqKSlRQkKCJGn27Nnq0aOHUlJSJJ27hmbYsGG66KKLVFZWpi1btujll1/WqlWr3NkMAADgIdwebmbNmqXDhw9r0aJFKigo0ODBg7V161b7Rcb5+fny9v5fB1NJSYnuuOMO/fe//5W/v78iIiK0YcMGzZo1y11NAAAAHsTLMAzD3UU0peLiYrVv315FRUVq166du8sBWozs7GxFRUXJarVq6NCh7i6nwczSDqC5qc/nt9t7bgCYS2lpqXJzc6ssz8nJcfjXmYiICAUEBLisNgAtA+EGQKPKzc1VVFRUtevj4uKqXUdvCIDGQLgB0KgiIiJktVqrLD916pTy8vIUFhYmf3//avcFgPNFuAHQqAICAqrtfRkzZkwTVwOgJWqWMxQDAABUh3ADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMxSPCzcqVKxUWFiY/Pz+NGDFC27Ztq3bbF198UdHR0erYsaM6duyomJiYGrcHAAAti9vDzcaNG5WUlKTFixcrOztbgwYNUmxsrA4dOuR0+4yMDF1//fX66KOPlJWVpdDQUP3617/Wjz/+2MSVAwAAT+RlGIbhzgJGjBihSy+9VM8995wkyWazKTQ0VL/73e/0wAMP1Lp/RUWFOnbsqOeee06zZ8+usr6srExlZWX2n4uLixUaGqqioiK1a9eu8RoCoEXIzs5WVFSUrFarhg4d6u5ygBajuLhY7du3r9Pnt1t7bsrLy2W1WhUTE2Nf5u3trZiYGGVlZdXpGKWlpTpz5ow6derkdH1KSorat29vf4SGhjZK7QAAwDO5NdwcOXJEFRUVCg4OdlgeHBysgoKCOh3j/vvvV/fu3R0C0s8lJyerqKjI/ti/f/951w0AADxXK3cXcD6eeOIJvfbaa8rIyJCfn5/TbXx9feXr69vElQEAAHdxa7gJCgqSxWJRYWGhw/LCwkKFhITUuO8zzzyjJ554Qh988IEGDhzoyjIBAEAz4tavpXx8fBQVFaX09HT7MpvNpvT0dI0aNara/Z566ik9+uij2rp1q4YNG9YUpQIAgGbC7V9LJSUlKT4+XsOGDdPw4cO1YsUKlZSUKCEhQZI0e/Zs9ejRQykpKZKkJ598UosWLdJf//pXhYWF2a/NCQwMVGBgoNvaAQAAPIPbw82sWbN0+PBhLVq0SAUFBRo8eLC2bt1qv8g4Pz9f3t7/62BatWqVysvLNWPGDIfjLF68WA8//HBTlg4AADyQ28ONJM2bN0/z5s1zui4jI8Ph57y8PNcXBAAAmi23z1AMAADQmAg3AADAVAg3AADAVAg3AADAVDzigmIA8DSlpaXKzc2tsjwnJ8fh31+KiIhQQECAS2sDUDPCDQA4kZubq6ioqGrXx8XFOV3O3cIB9yPcAIATERERslqtVZafOnVKeXl5CgsLk7+/v9P9ALiXl2EYhruLaErFxcVq3769ioqK1K5dO3eXAwAA6qA+n99cUAwAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyllbsLaGqVN0EvLi52cyUAAKCuKj+3Kz/Ha9Liws2JEyckSaGhoW6uBAAA1NeJEyfUvn37GrfxMuoSgUzEZrPpwIEDatu2rby8vFxyjuLiYoWGhmr//v1q166dS87RFMzQDjO0QTJHO8zQBol2eBIztEEyRzuaog2GYejEiRPq3r27vL1rvqqmxfXceHt7q2fPnk1yrnbt2jXbJ+rPmaEdZmiDZI52mKENEu3wJGZog2SOdri6DbX12FTigmIAAGAqhBsAAGAqhBsX8PX11eLFi+Xr6+vuUs6LGdphhjZI5miHGdog0Q5PYoY2SOZoh6e1ocVdUAwAAMyNnhsAAGAqhBsAAGAqhBsAAGAqhBsAAGAqhJsGuPnmm+Xl5aUnnnjCYfnmzZvtsx5nZGTIy8vL/vD399cll1yiP//5z+4oWdK5uqdNm+Z0XVhYmEOtYWFhmjlzpj788EOn2586dUqdOnVSUFCQysrKXFh1y1LX31FAQIAGDBigl156qWkLrEXla8PLy0utW7dWcHCwxo8fr9TUVNlstiqvC2ePjIwMt9Xs5eWlzp07a8KECfr666+rbHvrrbfKYrHo9ddfd3qs7777Trfccot69eolX19f9ejRQ1deeaVeeeUVnT171tVNqeKXv4/evXtrwYIFOn36tH0bZ7+Dyy67rMlrrU1WVpYsFosmTZrksDwvL8+hdh8fH4WHh+uxxx6r0z2ImkpBQYHmz5+v8PBw+fn5KTg4WGPGjNGqVatUWloqyfE1brFY1L17d82ZM0fHjh1zW92HDx/W7bffbn9Oh4SEKDY2Vo8//nidXsvr1q1Thw4dHI6Zk5Oj0NBQXXvttSovL3dJ3YSbBvLz89OTTz5Z65Nu165dOnjwoL799lvdeuutuv3225Went5EVdbPH/7wBx08eFC7du3SX/7yF3Xo0EExMTF6/PHHq2z7xhtv6JJLLlFERIQ2b97cpHXu379ft9xyi7p37y4fHx9dcMEFmj9/vn766Sf7NmPHjrW/wCo/ZKZMmaK0tLRqjxsRESFfX18VFBQ0RTMapPJ3tHPnTsXFxSkxMVH//Oc/3V2WgwkTJujgwYPKy8vTP//5T40bN07z58/X5MmTNXr0aB08eND+mDlzpn37ysfo0aPdVvPBgweVnp6uVq1aafLkyQ7blJaW6rXXXtOCBQuUmppa5Rjbtm3T0KFDlZOTo5UrV2rnzp3KyMjQ3LlztWrVKv3nP/9pquY4qGzbDz/8oOXLl+uFF17Q4sWLHbZZu3atw+/grbfeckutNVmzZo1+97vf6ZNPPtGBAweqrP/ggw908OBB7dmzR4888ogef/xxp78nd/jhhx80ZMgQvffee1qyZIm2b9+urKwsLViwQO+8844++OAD+7aVr/H8/Hy98sor+uSTT3TXXXe5rfZrrrlG27dv1/r167V792699dZbGjt2rAYMGNCg1/KXX36p6OhoTZgwQRs3bpSPj49rCjdQb/Hx8cbkyZONiIgI47777rMvf/PNN43K/9KPPvrIkGQcO3bMYd+LLrrIeOqpp5qyXLv4+Hhj6tSpTtddcMEFxvLly6ssX7RokeHt7W3k5uY6LB87dqyxevVqY9WqVcb48eNdUK1z33//vdG1a1fjsssuMzIyMox9+/YZW7ZsMS655BKjT58+xk8//WQYhmFcccUVRmJionHw4EFj//79RlZWlrFgwQKjdevWRmJiYpXjZmZmGr169TJuuOEG44knnmiy9vxSfX9HnTp1Mu6++27XF1ZH1dWfnp5uSDJefPHFOm3flJzVkJmZaUgyDh06ZF+2bt06Y+TIkcbx48eNgIAAIz8/377OZrMZkZGRRlRUlFFRUeH0PDabzSX118RZ26ZPn24MGTLE/rMk480332zawurpxIkTRmBgoJGbm2vMmjXLePzxx+3r9u7da0gytm/f7rDPlVdeadxxxx1NXKlzsbGxRs+ePY2TJ086XV/53HD2Gn/00UeNfv36ubpEp44dO2ZIMjIyMmrdtrrX8tq1a4327dsbhnHufSAwMNBYsGBBI1daFT03DWSxWLRkyRL96U9/0n//+99atzcMQ1u3blV+fr5GjBjRBBU2jvnz58swDP3973+3L/v++++VlZWlmTNnaubMmcrMzNS+ffuapJ4777xTPj4+eu+993TFFVeoV69euuqqq/TBBx/oxx9/1EMPPWTfNiAgQCEhIerZs6dGjhypJ598Ui+88IJefPFFh7+UpHN/Fd5www266aabPOavvZrYbDa98cYbOnbsmOv+8mlEv/rVrzRo0KAae848xcmTJ7VhwwaFh4erc+fO9uVr1qxRXFyc2rdvr6uuukrr1q2zr9uxY4dycnJ07733VntDP1fdqLc+du7cqc8++6xZPGd+7m9/+5siIiJ08cUXKy4uTqmpqTV+5fTvf/9bVqvVI95rf/rpJ7333nu688471aZNG6fbVPfc+PHHH/X222+7rR2BgYEKDAzU5s2bz/vygzfffFOTJk3SwoUL9eSTTzZShdUj3JyHq6++WoMHD67SxftzPXv2VGBgoHx8fDRp0iQtXrxYl19+eRNWeX46deqkrl27Ki8vz74sNTVVV111lTp27KhOnTopNjZWa9eudXktR48e1bvvvqs77rhD/v7+DutCQkJ04403auPGjTW+6cXHx6tjx44OH7InTpzQ66+/rri4OI0fP15FRUXKzMx0WTvOx/3336/AwED5+vpqxowZ6tixo+bOnevusuokIiLC4XnkSd555x37G3nbtm311ltvaePGjfagsmfPHn3++eeaNWuWJCkuLk5r1661P9d2794tSbr44ovtxzx06JD9mIGBgXr++eebuFXnVLbNz89PAwYM0KFDh3Tfffc5bHP99dc71NrUXzXXpjJYSue+ZisqKtLHH3/ssM3o0aPt77WXXnqpZs6cqdmzZ7ujXAffffedDMNweG5IUlBQkP3/+/7777cvr3yN+/v7q2fPnvLy8tKyZcuaumxJUqtWrbRu3TqtX79eHTp00JgxY/Tggw86vR6tJidPntS1116r++67z6GtrkS4OU9PPvmk1q9fr5ycHKfrMzMztWPHDu3YsUMvvfSSlixZolWrVjVxlefHMAz7XxYVFRVav369/Y1GOvdGv27dOtlsNpfWsWfPHhmGocjISKfrIyMjdezYMR0+fLjaY3h7e6tv374OH7Kvvfaa+vTpo0suuUQWi0XXXXed1qxZ09jlN4r77rtPO3bs0IcffqgRI0Zo+fLlCg8Pd3dZdfLz55GnGTdunP11um3bNsXGxuqqq66y90impqYqNjZWQUFBkqSJEyeqqKio2gvuJalz5872Y3bo0MFlF07WprJtX3zxheLj45WQkKBrrrnGYZvly5fba92xY4fGjx/vllqd2bVrl7Zt26brr79e0rkP3FmzZlV5jW7cuFE7duzQV199pb/97W/6+9//rgceeMAdJdfJtm3btGPHDl1yySUOvSKVr/Gvv/7afn3mpEmTVFFR4ZY6r7nmGh04cEBvvfWWJkyYoIyMDA0dOtSh57I2/v7+Gj9+vF588cVqPysbG+HmPF1++eWKjY1VcnKy0/W9e/dWeHi4LrnkEiUkJOimm25yeoGup/rpp590+PBh9e7dW5L07rvv6scff9SsWbPUqlUrtWrVStddd5327dvXZBdK19QzI6nWLvdffsimpqZWCWuvv/66Tpw4cX6FukBQUJDCw8MVHR2t119/XXfddZe+/fZbd5dVJzk5Ofbnkadp06aNwsPDFR4erksvvVQvvfSSSkpK9OKLL9oD/T/+8Q/7cz4gIEBHjx61f4XZp08fSec+iCtZLBb7MVu1auWWdkn/a9ugQYOUmpqqL774okowCAkJsdcaHh5e7dcn7rBmzRqdPXtW3bt3t///r1q1Sm+88YaKiors24WGhio8PFyRkZG69tpr9X//939aunSpw8gwdwgPD5eXl5fDc0OSLrzwQoWHh1fpha58jffp00e/+tWvtGLFCn322Wf66KOPmrJsB35+fho/frx+//vf67PPPtPNN99c4zcWv2SxWLR582YNHTpU48aNa5KAQ7hpBE888YTefvttZWVl1bqtxWLRqVOnmqCqxvHss8/K29vbPjx5zZo1uu666xz+ytuxY0eT9HZUvklU98LIyclRly5dqgw7/LmKigrt2bPH/iH77bff6vPPP9eCBQvsb5wjR460j4zxZKGhoZo1a1a1wdqTfPjhh/rmm2+q9Bh4Ki8vL3l7e+vUqVPasmWLTpw4oe3btzs851999VWlpaXp+PHjGjJkiCIiIvTMM8+4vAfzfHh7e+vBBx/UwoULm8X70NmzZ/WXv/xFS5cudfi//+qrr9S9e3e9+uqr1e5rsVh09uxZt/WYVercubPGjx+v5557TiUlJfXe32KxSJJH/b769etX77b4+voqLS1Nl156qcaNG+fyP8rc9+eEiQwYMEA33nij/vjHP1ZZd+jQIZ0+fVplZWXatm2bXn75Zc2YMcMNVZ5TVFSkHTt2OCyrvGjyxIkTKigo0JkzZ7R3715t2LBBL730klJSUhQeHq7Dhw/r7bff1ltvvaX+/fs7HGP27Nm6+uqrdfToUXXq1MkltVe+STz//PO6++67Hf7iKSgo0CuvvKI777yzxmOsX79ex44ds3/IrlmzRpdffrlWrlzpsN3atWu1Zs0aJSYmNn5DalHT7+iX5s+fr/79++vf//63hg0b1gTV1a6srEwFBQWqqKhQYWGhtm7dqpSUFE2ePNkjroFwprJmSTp27Jiee+45nTx5UlOmTNGKFSs0adIkDRo0yGGffv366e6777Y/79auXavx48drzJgxSk5OVmRkpM6cOaNPPvlEhw8ftn9IuVvltQ8rV67Uvffe6+5yavTOO+/o2LFjmjNnjtq3b++w7pprrtGaNWs0YcIESed6mQsKCnT27Fl98803evbZZzVu3Di1a9fOHaU7eP755zVmzBgNGzZMDz/8sAYOHChvb299+eWXys3NVVRUlH3byvdhwzC0f/9+LViwQF26dHHLFAk//fSTrr32Wt1yyy0aOHCg2rZtq3//+9966qmnNHXq1Hofz9fXV2+88YauvfZajRs3Th9++KEuueQSF1QuhoI3hLMhb3v37jV8fHyqDAWvfLRq1cro3bu3ce+991Y7HNDV4uPjHWqqfMyZM8e44IIL7D/7+PgYvXr1MmbOnGl8+OGH9v2feeYZo0OHDkZ5eXmVY5eVlRkdOnQwnn32WZe2Yffu3UZQUJARHR1tfPzxx0Z+fr7xz3/+0+jfv78xePBg48SJE4Zh1DwU/PbbbzcMwzDKy8uNLl26GKtWrapynm+//daQZOzcudOl7fml2n5Hzobrx8bGGldddVWT1lmdn9ffqlUro0uXLkZMTIyRmprqdIi0pwwF//n/ddu2bY1LL73U2LRpk1FQUGC0atXK+Nvf/uZ039tvv91hWPWuXbuM+Ph4o2fPnkarVq2M9u3bG5dffrnxwgsvGGfOnGmqJtlV9/+bkpJidOnSxTh58qRHDwWfPHmyMXHiRKfrvvjiC0OS8dVXXzn8/iwWi9GzZ08jMTHRYSi/ux04cMCYN2+e0bt3b6N169ZGYGCgMXz4cOPpp582SkpKDMMwHN6HJRldunQxJk6cWGWYe1M5ffq08cADDxhDhw412rdvbwQEBBgXX3yxsXDhQqO0tNRh27oMBa9UXl5uTJs2zejSpYvxzTffuKR2L8PwoCkcgTrIy8vTww8/rK1bt+rQoUMyDEPTp0/Xyy+/rICAAEnnJvGrHE3h4+Ojzp07KyoqSrfccouuvvpqSecmIpw5c6YOHDig4ODgKufp16+fJkyY4LaRCgCAhiHcoNlbvHixli1bpvfff18jR450dzkAADcj3MAU1q5dq6KiIt11113VTqIGAGgZCDcAAMBU+BMXAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGgOlkZGTIy8tLx48fr/M+YWFhWrFihctqAtB0CDcAmtzNN98sLy8v3XbbbVXW3XnnnfLy8tLNN9/c9IUBMAXCDQC3CA0N1WuvveZwt+PTp0/rr3/9q3r16uXGygA0d4QbAG4xdOhQhYaGKi0tzb4sLS1NvXr10pAhQ+zLysrKdNddd6lr167y8/PTZZddpi+//NLhWFu2bFHfvn3l7++vcePGKS8vr8r5Pv30U0VHR8vf31+hoaG66667VFJS4rQ2wzD08MMPq1evXvL19VX37t111113NU7DAbgc4QaA29xyyy1au3at/efU1FQlJCQ4bLNgwQK98cYbWr9+vbKzsxUeHq7Y2FgdPXpUkrR//35Nnz5dU6ZM0Y4dOzR37lw98MADDsf4/vvvNWHCBF1zzTX6+uuvtXHjRn366aeaN2+e07reeOMNLV++XC+88IL27NmjzZs3a8CAAY3cegAu45J7jQNADeLj442pU6cahw4dMnx9fY28vDwjLy/P8PPzMw4fPmxMnTrViI+PN06ePGm0bt3aeOWVV+z7lpeXG927dzeeeuopwzAMIzk52ejXr5/D8e+//35DknHs2DHDMAxjzpw5xm9/+1uHbTIzMw1vb2/j1KlThmEYxgUXXGAsX77cMAzDWLp0qdG3b1+jvLzcRf8DAFyJnhsAbtOlSxdNmjRJ69at09q1azVp0iQFBQXZ13///fc6c+aMxowZY1/WunVrDR8+XDk5OZKknJwcjRgxwuG4o0aNcvj5q6++0rp16xQYGGh/xMbGymazae/evVXquvbaa3Xq1CldeOGFSkxM1JtvvqmzZ882ZtMBuFArdxcAoGW75ZZb7F8PrVy50iXnOHnypG699Van1804u3g5NDRUu3bt0gcffKD3339fd9xxh55++ml9/PHHat26tUtqBNB46LkB4FYTJkxQeXm5zpw5o9jYWId1F110kXx8fPSvf/3LvuzMmTP68ssv1a9fP0lSZGSktm3b5rDf559/7vDz0KFD9e233yo8PLzKw8fHx2ld/v7+mjJliv74xz8qIyNDWVlZ+uabbxqjyQBcjJ4bAG5lsVjsXzFZLBaHdW3atNHtt9+u++67T506dVKvXr301FNPqbS0VHPmzJEk3XbbbVq6dKnuu+8+zZ07V1arVevWrXM4zv3336+RI0dq3rx5mjt3rtq0aaNvv/1W77//vp577rkqNa1bt04VFRUaMWKEAgICtGHDBvn7++uCCy5wzX8CgEZFzw0At2vXrp3atWvndN0TTzyha665RjfddJOGDh2q7777Tu+++646duwo6dzXSm+88YY2b96sQYMGafXq1VqyZInDMQYOHKiPP/5Yu3fvVnR0tIYMGaJFixape/fuTs/ZoUMHvfjiixozZowGDhyoDz74QG+//bY6d+7cuA0H4BJehmEY7i4CAACgsdBzAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATOX/Ab0bS3SLAgXXAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('Boxplot of \"accuracy\" over the different models:')\n",
        "acc_scatole = [nb_accurancy_test_k, lda_accurancy_test_k, qda_accurancy_test_k, lr_accurancy_test_k, cdt_accurancy_test_k, \n",
        "                bag_accurancy_test_k, rf_accurancy_test_k, ab_accurancy_test_k, gb_accurancy_test_k, stk_accurancy_test_k]\n",
        "plt.boxplot(acc_scatole)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(ticks=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
        "           labels=['NB', 'LDA', 'QDA', 'LR', 'DT', 'BAG', 'RF', 'AB', 'GB', 'STK'])\n",
        "plt.show()\n",
        "\n",
        "print('Boxplot of \"precision\" over the different models:')\n",
        "prec_scatole = [nb_precision_test_k, lda_precision_test_k, qda_precision_test_k, lr_precision_test_k, cdt_precision_test_k, \n",
        "                bag_precision_test_k, rf_precision_test_k, ab_precision_test_k, gb_precision_test_k, stk_precision_test_k]\n",
        "plt.boxplot(prec_scatole)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Precision')\n",
        "plt.xticks(ticks=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
        "           labels=['NB', 'LDA', 'QDA', 'LR', 'DT', 'BAG', 'RF', 'AB', 'GB', 'STK'])  # Set custom labels for the boxes\n",
        "plt.show()\n",
        "\n",
        "print('Boxplot of \"recall\" over the different models:')\n",
        "rec_scatole = [nb_recall_test_k, lda_recall_test_k, qda_recall_test_k, lr_recall_test_k, cdt_recall_test_k, \n",
        "                bag_recall_test_k, rf_recall_test_k, ab_recall_test_k, gb_recall_test_k, stk_recall_test_k]\n",
        "plt.boxplot(rec_scatole)\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Recall')\n",
        "plt.xticks(ticks=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
        "           labels=['NB', 'LDA', 'QDA', 'LR', 'DT', 'BAG', 'RF', 'AB', 'GB', 'STK'])  # Set custom labels for the boxes\n",
        "plt.show()\n",
        "\n",
        "print('Boxplot of \"F1-score\" over the different models:')\n",
        "F1_scatole = [nb_F1_score_test_k, lda_F1_score_test_k, qda_F1_score_test_k, lr_F1_score_test_k, cdt_F1_score_test_k, \n",
        "                bag_F1_score_test_k, rf_F1_score_test_k, ab_F1_score_test_k, gb_recall_test_k, stk_recall_test_k]\n",
        "plt.boxplot(rec_scatole)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('F1-score')\n",
        "plt.xticks(ticks=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \n",
        "           labels=['NB', 'LDA', 'QDA', 'LR', 'DT', 'BAG', 'RF', 'AB', 'GB', 'STK'])  # Set custom labels for the boxes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From our results, we can say that the simpler model tend to have more predictive power on the SAheart dataset; whereas LDA and QDA have a higher accuracy than the rest, Naive Bayes is the method that manages to keep a high recall without necessarily lacking accuracy (only 0.02 less than the discriminant analysis methods).\n",
        "\n",
        "If we had to choose between Classification Decision Tree, Bagging and Random Forest, we would pick the first one: all the metrics are clearly superior to the other methods (also computationally less expensive). Thus we deduce that this dataset tends to reward simpler methods. Also, it is worth noting that in the instances where RF had particularly low predictive power, the VIM on the training set was more unbalanced (this fact is coherent with the theory)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
